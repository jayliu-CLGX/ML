{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dea37c-036d-4a64-ba6d-88c15c276d45",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e4ccda-71c1-43c8-8463-df2cad1a56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd543c22-339a-44f6-826a-add905cf3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')  # Adjust based on your actual structure\n",
    "from config import DATA_DIR\n",
    "import pandas as pd\n",
    "import time\n",
    "from roof_condition_insights import RoofConditionInsights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd090180-12a4-4135-aa6b-3725fd4b5d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # multiprocess\n",
    "# -- UAT\n",
    "# rci = RoofConditionInsights(\n",
    "#     env=\"UAT\",\n",
    "#     api_key=\"FCC2638D0B8045FD81FA4DAD15E7D059\",\n",
    "#     api_companyid=\"340862391\",\n",
    "#     username=\"all@grange.com\",\n",
    "#     password=\"Myr1@d\"\n",
    "# )\n",
    "\n",
    "# df_roof_condition_insights = rci.process_multiple_addresses(addresses, generate_pdf=False, save_json=True)\n",
    "# -- PRD\n",
    "\n",
    "rci = RoofConditionInsights(\n",
    "    env=\"PRD\",\n",
    "    api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "    api_companyid=\"3168675050\",\n",
    "    username=\"all@vod.com\",\n",
    "    password=\"myriadvod123456\"\n",
    ")\n",
    "\n",
    "# -- Single Address\n",
    "address = \"3601 34TH AVE S, MINNEAPOLIS, MN 55406\"\n",
    "insights = rci.get_roof_condition_insights(address, generate_pdf=True)\n",
    "insights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52c7b12-5e60-4906-9eb7-7ef69471ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UAT credentials:\n",
    "# all@grange.com\n",
    "# Myr1@d\n",
    "\n",
    "# Api Key = FCC2638D0B8045FD81FA4DAD15E7D059\n",
    "# Company ID = 340862391\n",
    "\n",
    "# PRD \n",
    "# Api Key = 79802C81EF4C49C5A24F202BF3BB5219\n",
    "# Company ID = 3168675050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3914c-9d1c-409c-ba5d-063f02e9a25e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CHECK SCORE CALCULATIONS (roof score analysis.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dabc3a46-de49-4b80-8225-fbac9ae69abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DATA_DIR, 'datasets/input/roof score analysis.xlsx')\n",
    "rci_analysis = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437a3589-449c-47e1-a731-9adfc8417ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Y  (1-100) High = Best</th>\n",
       "      <th>Y Rating</th>\n",
       "      <th>Y Scaled High = Best</th>\n",
       "      <th>X  (1-5) High = Best</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>RCIv1.1 Scaled Low = Best</th>\n",
       "      <th>RCI V1.0 (0-10) Low = Best</th>\n",
       "      <th>Updated RCI score v1</th>\n",
       "      <th>RCI Score V1.1</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>RCI 1.0 Scaled</th>\n",
       "      <th>roof age</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>permits</th>\n",
       "      <th>hail score</th>\n",
       "      <th>hail event</th>\n",
       "      <th>wind</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106 N McKinley St. Casper WY, 82601</td>\n",
       "      <td>30.0</td>\n",
       "      <td>POOR</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>numberOfWindSpeedEventsGT60mph: 1,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980 Linda Vista Dr. Casper, WY 82609</td>\n",
       "      <td>80.0</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"numberOfWindSpeedEventsGT60mph\": 1,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3850 Swanton Ave. Casper, WY 82609</td>\n",
       "      <td>71.0</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"numberOfWindSpeedEventsGT60mph\": 1,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106 Tullulah Ave. River Ridge LA, 70123</td>\n",
       "      <td>15.0</td>\n",
       "      <td>VERY POOR</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>temp repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409 brighton ct Shreveport LA 71115</td>\n",
       "      <td>48.0</td>\n",
       "      <td>FAIR</td>\n",
       "      <td>2.40</td>\n",
       "      <td>5</td>\n",
       "      <td>Roof was replaced</td>\n",
       "      <td>roof discoloration, tree overhang</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tree overhang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"numberOfHailEventsGTE1InchLT2Inches\": 1,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Address  Y  (1-100) High = Best   Y Rating  \\\n",
       "0      106 N McKinley St. Casper WY, 82601                    30.0       POOR   \n",
       "1    1980 Linda Vista Dr. Casper, WY 82609                    80.0       GOOD   \n",
       "2       3850 Swanton Ave. Casper, WY 82609                    71.0       GOOD   \n",
       "3  106 Tullulah Ave. River Ridge LA, 70123                    15.0  VERY POOR   \n",
       "4      409 brighton ct Shreveport LA 71115                    48.0       FAIR   \n",
       "\n",
       "   Y Scaled High = Best X  (1-5) High = Best              Notes  \\\n",
       "0                  1.50                    4                NaN   \n",
       "1                  4.00                    5                NaN   \n",
       "2                  3.55                    5                NaN   \n",
       "3                  0.75                    1                NaN   \n",
       "4                  2.40                    5  Roof was replaced   \n",
       "\n",
       "                          Unnamed: 6  RCIv1.1 Scaled Low = Best  \\\n",
       "0                                NaN                       2.75   \n",
       "1                      tree overhang                       2.75   \n",
       "2                      tree overhang                       2.75   \n",
       "3                      tree overhang                       2.25   \n",
       "4  roof discoloration, tree overhang                       3.50   \n",
       "\n",
       "  RCI V1.0 (0-10) Low = Best  Updated RCI score v1  RCI Score V1.1  \\\n",
       "0                          1                   5.5             5.5   \n",
       "1                          1                   5.5             5.5   \n",
       "2                          1                   5.5             5.5   \n",
       "3                        4.5                   4.5             4.5   \n",
       "4                          1                   1.0             7.0   \n",
       "\n",
       "   Unnamed: 11  RCI 1.0 Scaled  roof age    Unnamed: 14 permits  hail score  \\\n",
       "0          4.5            0.50       7.0  tree overhang     NaN         0.0   \n",
       "1          4.5            0.50       8.0  tree overhang     NaN         0.0   \n",
       "2          4.5            0.50       8.0  tree overhang     NaN         0.0   \n",
       "3          0.0            2.25       7.0    temp repair     NaN         0.0   \n",
       "4          6.0            0.50       2.0  tree overhang     NaN         2.0   \n",
       "\n",
       "                                  hail event  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4  \"numberOfHailEventsGTE1InchLT2Inches\": 1,   \n",
       "\n",
       "                                     wind Unnamed: 19  \n",
       "0      numberOfWindSpeedEventsGT60mph: 1,         NaN  \n",
       "1    \"numberOfWindSpeedEventsGT60mph\": 1,         NaN  \n",
       "2    \"numberOfWindSpeedEventsGT60mph\": 1,         NaN  \n",
       "3                                     NaN         NaN  \n",
       "4                                     NaN         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rci_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c334cc-9243-4a9a-903f-d0a2dd0fea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = rci_analysis['Address'].dropna().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb65658-a9dc-4bd5-a7ac-7c89150210c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "Starting new run for 21 addresses using sequential processing...\n",
      "Created folder: /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0016\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m rci \u001b[38;5;241m=\u001b[39m RoofConditionInsights(\n\u001b[1;32m      2\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m79802C81EF4C49C5A24F202BF3BB5219\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmyriadvod123456\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m df_roof_condition_insights \u001b[38;5;241m=\u001b[39m \u001b[43mrci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_multiple_addresses\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/majid/roof-condition-insights/src/roof_condition_insights.py:495\u001b[0m, in \u001b[0;36mRoofConditionInsights.process_multiple_addresses\u001b[0;34m(self, addresses, chunk_size, generate_pdf, save_json, process_method, max_workers, retries)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid process_method. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# dfs.extend(chunk_dfs)\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# Save checkpoint for the current chunk\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m df_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_checkpoint(df_chunk, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, folder_name)\n\u001b[1;32m    497\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChunk (ind) [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m+\u001b[39mchunk_size,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(addresses))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Processed - Success: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28msum\u001b[39m(df_chunk\u001b[38;5;241m.\u001b[39mrun_completed)\u001b[38;5;241m/\u001b[39mdf_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/settleassist/lib/python3.9/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/conda/envs/settleassist/lib/python3.9/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/opt/conda/envs/settleassist/lib/python3.9/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "rci = RoofConditionInsights(\n",
    "    env=\"PRD\",\n",
    "    api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "    api_companyid=\"3168675050\",\n",
    "    username=\"all1@vod.com\",\n",
    "    password=\"myriadvod123456\"\n",
    ")\n",
    "\n",
    "df_roof_condition_insights = rci.process_multiple_addresses(addresses, generate_pdf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aff76b-9e3e-4050-8d8d-8aa480b3ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocess\n",
    "rci = RoofConditionInsights(\n",
    "    env=\"UAT\",\n",
    "    api_key=\"FCC2638D0B8045FD81FA4DAD15E7D059\",\n",
    "    api_companyid=\"340862391\",\n",
    "    username=\"all@grange.com\",\n",
    "    password=\"Myr1@d\"\n",
    ")\n",
    "import time\n",
    "st = time.time()\n",
    "df_roof_condition_insights = rci.process_multiple_addresses(addresses, generate_pdf=False, save_json=True)\n",
    "et = time.time()\n",
    "print('time', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04878755-0934-4bf8-88e8-ae0c29b0f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roof_condition_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c761c1-573c-4887-a3a0-41fd081f5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roof_condition_insights[[\"address\",\"score_v1.0\",\"score_v1.1\",\"key_triggers\",\"run_completed\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e4014-0334-49b2-9a1a-b3ea5b4e49a0",
   "metadata": {},
   "source": [
    "# UnderWriting Data Q4 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae25dcd9-7147-417a-83e8-b77950988249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UW_DATE</th>\n",
       "      <th>UW_NUMBER</th>\n",
       "      <th>UW_STREET</th>\n",
       "      <th>UW_CITY</th>\n",
       "      <th>UW_STATE</th>\n",
       "      <th>UW_ZIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-12 00:09:58</td>\n",
       "      <td>4761690126</td>\n",
       "      <td>427 LINDSEY ST</td>\n",
       "      <td>NEWPORT</td>\n",
       "      <td>KY</td>\n",
       "      <td>41071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-22 00:26:20</td>\n",
       "      <td>4820405436</td>\n",
       "      <td>1037 S BELLEVIEW PL</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>IN</td>\n",
       "      <td>46221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-12 00:27:51</td>\n",
       "      <td>4761871305</td>\n",
       "      <td>1419 S FLOYD ST</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>KY</td>\n",
       "      <td>40208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-12 00:12:25</td>\n",
       "      <td>4761720519</td>\n",
       "      <td>647 OAK ST</td>\n",
       "      <td>NEWPORT</td>\n",
       "      <td>KY</td>\n",
       "      <td>41071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27 00:32:24</td>\n",
       "      <td>4784166017</td>\n",
       "      <td>207 VARNER ST N</td>\n",
       "      <td>JORDAN</td>\n",
       "      <td>MN</td>\n",
       "      <td>55352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              UW_DATE   UW_NUMBER            UW_STREET       UW_CITY UW_STATE  \\\n",
       "0 2022-10-12 00:09:58  4761690126       427 LINDSEY ST       NEWPORT       KY   \n",
       "1 2022-11-22 00:26:20  4820405436  1037 S BELLEVIEW PL  INDIANAPOLIS       IN   \n",
       "2 2022-10-12 00:27:51  4761871305      1419 S FLOYD ST    LOUISVILLE       KY   \n",
       "3 2022-10-12 00:12:25  4761720519           647 OAK ST       NEWPORT       KY   \n",
       "4 2022-10-27 00:32:24  4784166017      207 VARNER ST N        JORDAN       MN   \n",
       "\n",
       "  UW_ZIP  \n",
       "0  41071  \n",
       "1  46221  \n",
       "2  40208  \n",
       "3  41071  \n",
       "4  55352  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "address_filepath = os.path.join(DATA_DIR, 'datasets/input/AS_Q4_2022.xlsx')\n",
    "dtype_dict = {\n",
    "    'UW_STREET': str,\n",
    "    'UW_CITY': str,\n",
    "    'UW_STATE': str,\n",
    "    'UW_ZIP': str\n",
    "}\n",
    "\n",
    "df_UW = pd.read_excel(address_filepath,\n",
    "                     dtype=dtype_dict)\n",
    "# df_UW['full_address'] = df_UW['UW_STREET'] + \", \" + df_UW['UW_CITY'] + \", \" + df_UW['UW_STATE'] + \" \" + df_UW['UW_ZIP'].astype(str)\n",
    "df_UW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df163b7-94fb-47b8-9de3-bf443159195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120933, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_UW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b6e9ac-7e56-48a3-b163-27020ca3ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary lowercase columns for comparison\n",
    "lowercase_cols = ['UW_STREET_lower', 'UW_CITY_lower', 'UW_STATE_lower', 'UW_ZIP_lower']\n",
    "for col, lowercase_col in zip(['UW_STREET', 'UW_CITY', 'UW_STATE', 'UW_ZIP'], lowercase_cols):\n",
    "    df_UW[lowercase_col] = df_UW[col].str.lower()\n",
    "# Drop duplicates based on lowercase columns\n",
    "df_UW = df_UW.drop_duplicates(subset=lowercase_cols, keep='first')\n",
    "df_UW.drop(columns=lowercase_cols, inplace=True)\n",
    "df_UW.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a22ce08-603b-4ea7-8390-da3ad5884845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98434, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_UW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f187c4-24fb-44c7-adfb-dff89ce943c2",
   "metadata": {},
   "source": [
    "# Claims Data 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed248e5-55b7-4caa-8f91-a496d51c0258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_date</th>\n",
       "      <th>last_date</th>\n",
       "      <th>claim_count</th>\n",
       "      <th>claim_number</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>full_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-23 07:58:00</td>\n",
       "      <td>2023-09-23 08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>484537667</td>\n",
       "      <td>2045 CLEARWATER LOOP NE</td>\n",
       "      <td>RIO RANCHO</td>\n",
       "      <td>NM</td>\n",
       "      <td>87144-5559</td>\n",
       "      <td>2045 CLEARWATER LOOP NE, RIO RANCHO, NM 87144-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-08 08:39:00</td>\n",
       "      <td>2023-10-08 08:45:00</td>\n",
       "      <td>2</td>\n",
       "      <td>523643906</td>\n",
       "      <td>7023 BOLELYN WAY</td>\n",
       "      <td>HENRICO</td>\n",
       "      <td>VA</td>\n",
       "      <td>232317277</td>\n",
       "      <td>7023 BOLELYN WAY, HENRICO, VA 232317277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04 15:49:00</td>\n",
       "      <td>2023-01-04 16:50:00</td>\n",
       "      <td>2</td>\n",
       "      <td>535912083</td>\n",
       "      <td>3414 CASCADIA DR.</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TX</td>\n",
       "      <td>77082-1441</td>\n",
       "      <td>3414 CASCADIA DR., HOUSTON, TX 77082-1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-04 13:50:00</td>\n",
       "      <td>2023-09-04 13:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>536551195</td>\n",
       "      <td>89 HICKORY CT</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>KY</td>\n",
       "      <td>40051-6122</td>\n",
       "      <td>89 HICKORY CT, NEW HAVEN, KY 40051-6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-14 10:33:00</td>\n",
       "      <td>2023-08-14 10:33:00</td>\n",
       "      <td>1</td>\n",
       "      <td>548825157</td>\n",
       "      <td>1147 82ND ST SW</td>\n",
       "      <td>ALBUQUERQUE</td>\n",
       "      <td>NM</td>\n",
       "      <td>87121-2089</td>\n",
       "      <td>1147 82ND ST SW, ALBUQUERQUE, NM 87121-2089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           first_date           last_date  claim_count claim_number  \\\n",
       "0 2023-09-23 07:58:00 2023-09-23 08:00:00            2    484537667   \n",
       "1 2023-10-08 08:39:00 2023-10-08 08:45:00            2    523643906   \n",
       "2 2023-01-04 15:49:00 2023-01-04 16:50:00            2    535912083   \n",
       "3 2023-09-04 13:50:00 2023-09-04 13:50:00            1    536551195   \n",
       "4 2023-08-14 10:33:00 2023-08-14 10:33:00            1    548825157   \n",
       "\n",
       "                    street         city state         zip  \\\n",
       "0  2045 CLEARWATER LOOP NE   RIO RANCHO    NM  87144-5559   \n",
       "1         7023 BOLELYN WAY      HENRICO    VA   232317277   \n",
       "2        3414 CASCADIA DR.      HOUSTON    TX  77082-1441   \n",
       "3            89 HICKORY CT    NEW HAVEN    KY  40051-6122   \n",
       "4          1147 82ND ST SW  ALBUQUERQUE    NM  87121-2089   \n",
       "\n",
       "                                        full_address  \n",
       "0  2045 CLEARWATER LOOP NE, RIO RANCHO, NM 87144-...  \n",
       "1            7023 BOLELYN WAY, HENRICO, VA 232317277  \n",
       "2          3414 CASCADIA DR., HOUSTON, TX 77082-1441  \n",
       "3            89 HICKORY CT, NEW HAVEN, KY 40051-6122  \n",
       "4        1147 82ND ST SW, ALBUQUERQUE, NM 87121-2089  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read 2023 claim data\n",
    "import pandas as pd\n",
    "claim_filepath = os.path.join(DATA_DIR, 'datasets/input/2023_Allstate_Claims_Data_Export.xlsx')\n",
    "\n",
    "dtype_dict = {\n",
    "    'street': str,\n",
    "    'city': str,\n",
    "    'state': str,\n",
    "    'zip': str\n",
    "}\n",
    "df_claims = pd.read_excel(claim_filepath, dtype=dtype_dict)\n",
    "df_claims['full_address'] = df_claims['street'].astype(str) + \", \" + df_claims['city'].astype(str) + \", \" + df_claims['state'].astype(str) + \" \" + df_claims['zip'].astype(str)\n",
    "# Filter rows NOT containing 'test' or 'train'\n",
    "df_claims['claim_number'] = df_claims['claim_number'].astype(str)\n",
    "df_claims = df_claims[~df_claims['claim_number'].str.contains('test|train|automation', case=False)]\n",
    "\n",
    "df_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5207c852-3461-4956-9a95-555481c55079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293248, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679a5103-c666-4014-9342-b3d1a52a3983",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281975, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>claim_numbers</th>\n",
       "      <th>claim_row_count</th>\n",
       "      <th>claim_counts</th>\n",
       "      <th>min_first_date</th>\n",
       "      <th>max_first_date</th>\n",
       "      <th>first_dates</th>\n",
       "      <th>min_last_date</th>\n",
       "      <th>max_last_date</th>\n",
       "      <th>last_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88408</th>\n",
       "      <td>1M Galaxy</td>\n",
       "      <td>Easy</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>[EHS-481_13-01-2023, EBB-510_13-01-2023, YTV-5...</td>\n",
       "      <td>183</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, ...</td>\n",
       "      <td>2023-01-13 15:28:00</td>\n",
       "      <td>2023-12-15 05:08:00</td>\n",
       "      <td>[2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...</td>\n",
       "      <td>2023-01-13 15:28:00</td>\n",
       "      <td>2023-12-15 05:08:00</td>\n",
       "      <td>[2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88405</th>\n",
       "      <td>1L Galaxy</td>\n",
       "      <td>Easy</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>[ha0223ALL a p, ha0223ALL i p, HJA111102230917...</td>\n",
       "      <td>23</td>\n",
       "      <td>[3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>2023-02-23 13:28:00</td>\n",
       "      <td>2023-12-14 19:46:00</td>\n",
       "      <td>[2023-02-23 13:28:00, 2023-02-23 13:28:00, 202...</td>\n",
       "      <td>2023-02-23 13:29:00</td>\n",
       "      <td>2023-12-14 19:54:00</td>\n",
       "      <td>[2023-02-23 13:29:00, 2023-02-23 13:29:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35606</th>\n",
       "      <td>123 Hover Street</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30005</td>\n",
       "      <td>[WJ0000000312, WJ0000000313, WJ0000000315, WJ0...</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>2023-06-05 07:48:00</td>\n",
       "      <td>2023-07-21 09:41:00</td>\n",
       "      <td>[2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...</td>\n",
       "      <td>2023-06-05 07:48:00</td>\n",
       "      <td>2023-07-21 09:41:00</td>\n",
       "      <td>[2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>100 Prairie Lane</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>80203</td>\n",
       "      <td>[14141414, 7172023, 7182023, 9012023, 08312023...</td>\n",
       "      <td>6</td>\n",
       "      <td>[2, 2, 1, 1, 1, 1]</td>\n",
       "      <td>2023-06-30 10:25:00</td>\n",
       "      <td>2023-09-29 14:08:00</td>\n",
       "      <td>[2023-06-30 10:25:00, 2023-07-17 13:57:00, 202...</td>\n",
       "      <td>2023-06-30 12:26:00</td>\n",
       "      <td>2023-09-29 14:08:00</td>\n",
       "      <td>[2023-06-30 12:26:00, 2023-07-17 14:13:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168229</th>\n",
       "      <td>390 CLAUDIA LN</td>\n",
       "      <td>MIDWAY</td>\n",
       "      <td>GA</td>\n",
       "      <td>31320-3252</td>\n",
       "      <td>[703932376, 722612066, 724730809, 726847882, 7...</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>2023-02-28 12:34:00</td>\n",
       "      <td>2023-10-21 07:18:00</td>\n",
       "      <td>[2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...</td>\n",
       "      <td>2023-02-28 12:34:00</td>\n",
       "      <td>2023-10-21 07:18:00</td>\n",
       "      <td>[2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95868</th>\n",
       "      <td>208 AMY CT</td>\n",
       "      <td>STROUDSBURG</td>\n",
       "      <td>PA</td>\n",
       "      <td>18360-9166</td>\n",
       "      <td>[708889258]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2023-04-04 11:26:00</td>\n",
       "      <td>2023-04-04 11:26:00</td>\n",
       "      <td>[2023-04-04 11:26:00]</td>\n",
       "      <td>2023-04-04 13:42:00</td>\n",
       "      <td>2023-04-04 13:42:00</td>\n",
       "      <td>[2023-04-04 13:42:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95867</th>\n",
       "      <td>208 AMES BURY POINTE</td>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29501-8508</td>\n",
       "      <td>[719810888]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-06-30 15:14:00</td>\n",
       "      <td>2023-06-30 15:14:00</td>\n",
       "      <td>[2023-06-30 15:14:00]</td>\n",
       "      <td>2023-06-30 15:14:00</td>\n",
       "      <td>2023-06-30 15:14:00</td>\n",
       "      <td>[2023-06-30 15:14:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95866</th>\n",
       "      <td>208 ALREVA RD</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>KY</td>\n",
       "      <td>40216-1502</td>\n",
       "      <td>[709129266]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2023-04-08 08:54:00</td>\n",
       "      <td>2023-04-08 08:54:00</td>\n",
       "      <td>[2023-04-08 08:54:00]</td>\n",
       "      <td>2023-04-08 08:55:00</td>\n",
       "      <td>2023-04-08 08:55:00</td>\n",
       "      <td>[2023-04-08 08:55:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95865</th>\n",
       "      <td>208 ALLEN DR</td>\n",
       "      <td>EXTON</td>\n",
       "      <td>PA</td>\n",
       "      <td>19341-1769</td>\n",
       "      <td>[715754404]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2023-05-30 13:24:00</td>\n",
       "      <td>2023-05-30 13:24:00</td>\n",
       "      <td>[2023-05-30 13:24:00]</td>\n",
       "      <td>2023-05-30 14:43:00</td>\n",
       "      <td>2023-05-30 14:43:00</td>\n",
       "      <td>[2023-05-30 14:43:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95873</th>\n",
       "      <td>208 ASHLEY DANIELLE DR</td>\n",
       "      <td>DUNCAN</td>\n",
       "      <td>SC</td>\n",
       "      <td>29334-8960</td>\n",
       "      <td>[702394065]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-02-11 07:22:00</td>\n",
       "      <td>2023-02-11 07:22:00</td>\n",
       "      <td>[2023-02-11 07:22:00]</td>\n",
       "      <td>2023-02-11 07:22:00</td>\n",
       "      <td>2023-02-11 07:22:00</td>\n",
       "      <td>[2023-02-11 07:22:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281975 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        street         city state         zip  \\\n",
       "88408                1M Galaxy         Easy    CO       80022   \n",
       "88405                1L Galaxy         Easy    CO       80022   \n",
       "35606         123 Hover Street   Alpharetta    GA       30005   \n",
       "1170          100 Prairie Lane       Denver    CO       80203   \n",
       "168229          390 CLAUDIA LN       MIDWAY    GA  31320-3252   \n",
       "...                        ...          ...   ...         ...   \n",
       "95868               208 AMY CT  STROUDSBURG    PA  18360-9166   \n",
       "95867     208 AMES BURY POINTE     FLORENCE    SC  29501-8508   \n",
       "95866            208 ALREVA RD   LOUISVILLE    KY  40216-1502   \n",
       "95865             208 ALLEN DR        EXTON    PA  19341-1769   \n",
       "95873   208 ASHLEY DANIELLE DR       DUNCAN    SC  29334-8960   \n",
       "\n",
       "                                            claim_numbers  claim_row_count  \\\n",
       "88408   [EHS-481_13-01-2023, EBB-510_13-01-2023, YTV-5...              183   \n",
       "88405   [ha0223ALL a p, ha0223ALL i p, HJA111102230917...               23   \n",
       "35606   [WJ0000000312, WJ0000000313, WJ0000000315, WJ0...                9   \n",
       "1170    [14141414, 7172023, 7182023, 9012023, 08312023...                6   \n",
       "168229  [703932376, 722612066, 724730809, 726847882, 7...                6   \n",
       "...                                                   ...              ...   \n",
       "95868                                         [708889258]                1   \n",
       "95867                                         [719810888]                1   \n",
       "95866                                         [709129266]                1   \n",
       "95865                                         [715754404]                1   \n",
       "95873                                         [702394065]                1   \n",
       "\n",
       "                                             claim_counts      min_first_date  \\\n",
       "88408   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, ... 2023-01-13 15:28:00   \n",
       "88405   [3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ... 2023-02-23 13:28:00   \n",
       "35606                         [1, 1, 1, 1, 1, 2, 1, 1, 1] 2023-06-05 07:48:00   \n",
       "1170                                   [2, 2, 1, 1, 1, 1] 2023-06-30 10:25:00   \n",
       "168229                                 [1, 1, 2, 1, 1, 1] 2023-02-28 12:34:00   \n",
       "...                                                   ...                 ...   \n",
       "95868                                                 [2] 2023-04-04 11:26:00   \n",
       "95867                                                 [1] 2023-06-30 15:14:00   \n",
       "95866                                                 [2] 2023-04-08 08:54:00   \n",
       "95865                                                 [2] 2023-05-30 13:24:00   \n",
       "95873                                                 [1] 2023-02-11 07:22:00   \n",
       "\n",
       "            max_first_date                                        first_dates  \\\n",
       "88408  2023-12-15 05:08:00  [2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...   \n",
       "88405  2023-12-14 19:46:00  [2023-02-23 13:28:00, 2023-02-23 13:28:00, 202...   \n",
       "35606  2023-07-21 09:41:00  [2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...   \n",
       "1170   2023-09-29 14:08:00  [2023-06-30 10:25:00, 2023-07-17 13:57:00, 202...   \n",
       "168229 2023-10-21 07:18:00  [2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...   \n",
       "...                    ...                                                ...   \n",
       "95868  2023-04-04 11:26:00                              [2023-04-04 11:26:00]   \n",
       "95867  2023-06-30 15:14:00                              [2023-06-30 15:14:00]   \n",
       "95866  2023-04-08 08:54:00                              [2023-04-08 08:54:00]   \n",
       "95865  2023-05-30 13:24:00                              [2023-05-30 13:24:00]   \n",
       "95873  2023-02-11 07:22:00                              [2023-02-11 07:22:00]   \n",
       "\n",
       "             min_last_date       max_last_date  \\\n",
       "88408  2023-01-13 15:28:00 2023-12-15 05:08:00   \n",
       "88405  2023-02-23 13:29:00 2023-12-14 19:54:00   \n",
       "35606  2023-06-05 07:48:00 2023-07-21 09:41:00   \n",
       "1170   2023-06-30 12:26:00 2023-09-29 14:08:00   \n",
       "168229 2023-02-28 12:34:00 2023-10-21 07:18:00   \n",
       "...                    ...                 ...   \n",
       "95868  2023-04-04 13:42:00 2023-04-04 13:42:00   \n",
       "95867  2023-06-30 15:14:00 2023-06-30 15:14:00   \n",
       "95866  2023-04-08 08:55:00 2023-04-08 08:55:00   \n",
       "95865  2023-05-30 14:43:00 2023-05-30 14:43:00   \n",
       "95873  2023-02-11 07:22:00 2023-02-11 07:22:00   \n",
       "\n",
       "                                               last_dates  \n",
       "88408   [2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...  \n",
       "88405   [2023-02-23 13:29:00, 2023-02-23 13:29:00, 202...  \n",
       "35606   [2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...  \n",
       "1170    [2023-06-30 12:26:00, 2023-07-17 14:13:00, 202...  \n",
       "168229  [2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...  \n",
       "...                                                   ...  \n",
       "95868                               [2023-04-04 13:42:00]  \n",
       "95867                               [2023-06-30 15:14:00]  \n",
       "95866                               [2023-04-08 08:55:00]  \n",
       "95865                               [2023-05-30 14:43:00]  \n",
       "95873                               [2023-02-11 07:22:00]  \n",
       "\n",
       "[281975 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deup claims\n",
    "df_claims['first_date'] = pd.to_datetime(df_claims['first_date'])\n",
    "df_claims['last_date'] = pd.to_datetime(df_claims['last_date'])\n",
    "# sort by 'first_date'\n",
    "df_claims = df_claims.sort_values('first_date').reset_index(drop=True)\n",
    "# Group by 'full_address' and aggregate data\n",
    "grouped = df_claims.groupby(['street', 'city', 'state', 'zip']).agg({\n",
    "    'claim_number': lambda x: list(x),\n",
    "    'claim_count': ['count', lambda x: list(x)],\n",
    "    'first_date': ['min', 'max', lambda x: list(x)],\n",
    "    'last_date': ['min', 'max', lambda x: list(x)]\n",
    "}).reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "grouped.columns = ['street', 'city', 'state', 'zip',\n",
    "    'claim_numbers', 'claim_row_count', 'claim_counts',\n",
    "    'min_first_date', 'max_first_date', 'first_dates',\n",
    "    'min_last_date', 'max_last_date', 'last_dates'\n",
    "]\n",
    "\n",
    "print(grouped.shape)\n",
    "grouped.sort_values('claim_row_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4477ecf8-9267-440e-88b7-d367b3605321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the aggregated data back with the original DataFrame, deduplicating by 'full_address'\n",
    "df_claims_dedup = df_claims.drop_duplicates(subset=['street', 'city', 'state', 'zip'], keep='first')\n",
    "df_claims_deduped = pd.merge(df_claims_dedup[['street', 'city', 'state', 'zip']], \n",
    "                             grouped, \n",
    "                             on=['street', 'city', 'state', 'zip'], \n",
    "                             how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1cb3c7c-4a9d-47d3-b12a-e3e768d2564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>claim_numbers</th>\n",
       "      <th>claim_row_count</th>\n",
       "      <th>claim_counts</th>\n",
       "      <th>min_first_date</th>\n",
       "      <th>max_first_date</th>\n",
       "      <th>first_dates</th>\n",
       "      <th>min_last_date</th>\n",
       "      <th>max_last_date</th>\n",
       "      <th>last_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2A DEER TRAIL</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>PA</td>\n",
       "      <td>17320-8125</td>\n",
       "      <td>[697893212]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>2023-01-01 04:17:00</td>\n",
       "      <td>2023-01-01 04:17:00</td>\n",
       "      <td>[2023-01-01 04:17:00]</td>\n",
       "      <td>2023-01-01 04:20:00</td>\n",
       "      <td>2023-01-01 04:20:00</td>\n",
       "      <td>[2023-01-01 04:20:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2608 COCHRANE DR</td>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>NC</td>\n",
       "      <td>28269-4041</td>\n",
       "      <td>[695384248]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>[2023-01-01 06:03:00]</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>[2023-01-01 06:03:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113 WINDSTONE DR</td>\n",
       "      <td>COLUMBIA</td>\n",
       "      <td>SC</td>\n",
       "      <td>29212-2148</td>\n",
       "      <td>[697026300]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>[2023-01-01 06:47:00]</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>[2023-01-01 06:47:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11258 HGY 64</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>TN</td>\n",
       "      <td>38002</td>\n",
       "      <td>[697209807]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>[2023-01-01 08:10:00]</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>[2023-01-01 08:10:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510 SHILOH APT 301</td>\n",
       "      <td>LAREDO</td>\n",
       "      <td>TX</td>\n",
       "      <td>78045-6702</td>\n",
       "      <td>[697739688]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2023-01-01 08:12:00</td>\n",
       "      <td>2023-01-01 08:12:00</td>\n",
       "      <td>[2023-01-01 08:12:00]</td>\n",
       "      <td>2023-01-06 14:50:00</td>\n",
       "      <td>2023-01-06 14:50:00</td>\n",
       "      <td>[2023-01-06 14:50:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               street       city state         zip claim_numbers  \\\n",
       "0       2A DEER TRAIL  FAIRFIELD    PA  17320-8125   [697893212]   \n",
       "1    2608 COCHRANE DR  CHARLOTTE    NC  28269-4041   [695384248]   \n",
       "2    113 WINDSTONE DR   COLUMBIA    SC  29212-2148   [697026300]   \n",
       "3        11258 HGY 64  ARLINGTON    TN       38002   [697209807]   \n",
       "4  510 SHILOH APT 301     LAREDO    TX  78045-6702   [697739688]   \n",
       "\n",
       "   claim_row_count claim_counts      min_first_date      max_first_date  \\\n",
       "0              1.0          [3] 2023-01-01 04:17:00 2023-01-01 04:17:00   \n",
       "1              1.0          [1] 2023-01-01 06:03:00 2023-01-01 06:03:00   \n",
       "2              1.0          [1] 2023-01-01 06:47:00 2023-01-01 06:47:00   \n",
       "3              1.0          [1] 2023-01-01 08:10:00 2023-01-01 08:10:00   \n",
       "4              1.0          [2] 2023-01-01 08:12:00 2023-01-01 08:12:00   \n",
       "\n",
       "             first_dates       min_last_date       max_last_date  \\\n",
       "0  [2023-01-01 04:17:00] 2023-01-01 04:20:00 2023-01-01 04:20:00   \n",
       "1  [2023-01-01 06:03:00] 2023-01-01 06:03:00 2023-01-01 06:03:00   \n",
       "2  [2023-01-01 06:47:00] 2023-01-01 06:47:00 2023-01-01 06:47:00   \n",
       "3  [2023-01-01 08:10:00] 2023-01-01 08:10:00 2023-01-01 08:10:00   \n",
       "4  [2023-01-01 08:12:00] 2023-01-06 14:50:00 2023-01-06 14:50:00   \n",
       "\n",
       "              last_dates  \n",
       "0  [2023-01-01 04:20:00]  \n",
       "1  [2023-01-01 06:03:00]  \n",
       "2  [2023-01-01 06:47:00]  \n",
       "3  [2023-01-01 08:10:00]  \n",
       "4  [2023-01-06 14:50:00]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_deduped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa56273-eefe-495b-8103-9093e68dbc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281977, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_deduped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc2abe1-ec30-4a2b-a4f6-e82c221d9b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>claim_numbers</th>\n",
       "      <th>claim_row_count</th>\n",
       "      <th>claim_counts</th>\n",
       "      <th>min_first_date</th>\n",
       "      <th>max_first_date</th>\n",
       "      <th>first_dates</th>\n",
       "      <th>min_last_date</th>\n",
       "      <th>max_last_date</th>\n",
       "      <th>last_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2A DEER TRAIL</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>PA</td>\n",
       "      <td>17320-8125</td>\n",
       "      <td>[697893212]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>2023-01-01 04:17:00</td>\n",
       "      <td>2023-01-01 04:17:00</td>\n",
       "      <td>[2023-01-01 04:17:00]</td>\n",
       "      <td>2023-01-01 04:20:00</td>\n",
       "      <td>2023-01-01 04:20:00</td>\n",
       "      <td>[2023-01-01 04:20:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2608 COCHRANE DR</td>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>NC</td>\n",
       "      <td>28269-4041</td>\n",
       "      <td>[695384248]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>[2023-01-01 06:03:00]</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>[2023-01-01 06:03:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113 WINDSTONE DR</td>\n",
       "      <td>COLUMBIA</td>\n",
       "      <td>SC</td>\n",
       "      <td>29212-2148</td>\n",
       "      <td>[697026300]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>[2023-01-01 06:47:00]</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>[2023-01-01 06:47:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11258 HGY 64</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>TN</td>\n",
       "      <td>38002</td>\n",
       "      <td>[697209807]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>[2023-01-01 08:10:00]</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>[2023-01-01 08:10:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510 SHILOH APT 301</td>\n",
       "      <td>LAREDO</td>\n",
       "      <td>TX</td>\n",
       "      <td>78045-6702</td>\n",
       "      <td>[697739688]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2023-01-01 08:12:00</td>\n",
       "      <td>2023-01-01 08:12:00</td>\n",
       "      <td>[2023-01-01 08:12:00]</td>\n",
       "      <td>2023-01-06 14:50:00</td>\n",
       "      <td>2023-01-06 14:50:00</td>\n",
       "      <td>[2023-01-06 14:50:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               street       city state         zip claim_numbers  \\\n",
       "0       2A DEER TRAIL  FAIRFIELD    PA  17320-8125   [697893212]   \n",
       "1    2608 COCHRANE DR  CHARLOTTE    NC  28269-4041   [695384248]   \n",
       "2    113 WINDSTONE DR   COLUMBIA    SC  29212-2148   [697026300]   \n",
       "3        11258 HGY 64  ARLINGTON    TN       38002   [697209807]   \n",
       "4  510 SHILOH APT 301     LAREDO    TX  78045-6702   [697739688]   \n",
       "\n",
       "   claim_row_count claim_counts      min_first_date      max_first_date  \\\n",
       "0              1.0          [3] 2023-01-01 04:17:00 2023-01-01 04:17:00   \n",
       "1              1.0          [1] 2023-01-01 06:03:00 2023-01-01 06:03:00   \n",
       "2              1.0          [1] 2023-01-01 06:47:00 2023-01-01 06:47:00   \n",
       "3              1.0          [1] 2023-01-01 08:10:00 2023-01-01 08:10:00   \n",
       "4              1.0          [2] 2023-01-01 08:12:00 2023-01-01 08:12:00   \n",
       "\n",
       "             first_dates       min_last_date       max_last_date  \\\n",
       "0  [2023-01-01 04:17:00] 2023-01-01 04:20:00 2023-01-01 04:20:00   \n",
       "1  [2023-01-01 06:03:00] 2023-01-01 06:03:00 2023-01-01 06:03:00   \n",
       "2  [2023-01-01 06:47:00] 2023-01-01 06:47:00 2023-01-01 06:47:00   \n",
       "3  [2023-01-01 08:10:00] 2023-01-01 08:10:00 2023-01-01 08:10:00   \n",
       "4  [2023-01-01 08:12:00] 2023-01-06 14:50:00 2023-01-06 14:50:00   \n",
       "\n",
       "              last_dates  \n",
       "0  [2023-01-01 04:20:00]  \n",
       "1  [2023-01-01 06:03:00]  \n",
       "2  [2023-01-01 06:47:00]  \n",
       "3  [2023-01-01 08:10:00]  \n",
       "4  [2023-01-06 14:50:00]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_deduped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9c5f076-9c71-4b85-99cb-2a099817a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_count = df_claims.groupby(['street', 'city', 'state', 'zip']).size().reset_index(name='claim_row_count')\n",
    "deduped_df = df_claims.drop_duplicates(subset=['street', 'city', 'state', 'zip'], keep='first')\n",
    "df_claims_deduped_simple = pd.merge(deduped_df, group_count, on=['street', 'city', 'state', 'zip'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17265278-1f18-4078-b9da-c3bc6e6b9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281977, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_deduped_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6baa08b-3d2b-4d49-83f1-bf3880804655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_date</th>\n",
       "      <th>last_date</th>\n",
       "      <th>claim_count</th>\n",
       "      <th>claim_number</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>full_address</th>\n",
       "      <th>claim_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 04:17:00</td>\n",
       "      <td>2023-01-01 04:20:00</td>\n",
       "      <td>3</td>\n",
       "      <td>697893212</td>\n",
       "      <td>2A DEER TRAIL</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>PA</td>\n",
       "      <td>17320-8125</td>\n",
       "      <td>2A DEER TRAIL, FAIRFIELD, PA 17320-8125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>2023-01-01 06:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>695384248</td>\n",
       "      <td>2608 COCHRANE DR</td>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>NC</td>\n",
       "      <td>28269-4041</td>\n",
       "      <td>2608 COCHRANE DR, CHARLOTTE, NC 28269-4041</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>2023-01-01 06:47:00</td>\n",
       "      <td>1</td>\n",
       "      <td>697026300</td>\n",
       "      <td>113 WINDSTONE DR</td>\n",
       "      <td>COLUMBIA</td>\n",
       "      <td>SC</td>\n",
       "      <td>29212-2148</td>\n",
       "      <td>113 WINDSTONE DR, COLUMBIA, SC 29212-2148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>2023-01-01 08:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>697209807</td>\n",
       "      <td>11258 HGY 64</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>TN</td>\n",
       "      <td>38002</td>\n",
       "      <td>11258 HGY 64, ARLINGTON, TN 38002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 08:12:00</td>\n",
       "      <td>2023-01-06 14:50:00</td>\n",
       "      <td>2</td>\n",
       "      <td>697739688</td>\n",
       "      <td>510 SHILOH APT 301</td>\n",
       "      <td>LAREDO</td>\n",
       "      <td>TX</td>\n",
       "      <td>78045-6702</td>\n",
       "      <td>510 SHILOH APT 301, LAREDO, TX 78045-6702</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           first_date           last_date  claim_count claim_number  \\\n",
       "0 2023-01-01 04:17:00 2023-01-01 04:20:00            3    697893212   \n",
       "1 2023-01-01 06:03:00 2023-01-01 06:03:00            1    695384248   \n",
       "2 2023-01-01 06:47:00 2023-01-01 06:47:00            1    697026300   \n",
       "3 2023-01-01 08:10:00 2023-01-01 08:10:00            1    697209807   \n",
       "4 2023-01-01 08:12:00 2023-01-06 14:50:00            2    697739688   \n",
       "\n",
       "               street       city state         zip  \\\n",
       "0       2A DEER TRAIL  FAIRFIELD    PA  17320-8125   \n",
       "1    2608 COCHRANE DR  CHARLOTTE    NC  28269-4041   \n",
       "2    113 WINDSTONE DR   COLUMBIA    SC  29212-2148   \n",
       "3        11258 HGY 64  ARLINGTON    TN       38002   \n",
       "4  510 SHILOH APT 301     LAREDO    TX  78045-6702   \n",
       "\n",
       "                                 full_address  claim_row_count  \n",
       "0     2A DEER TRAIL, FAIRFIELD, PA 17320-8125              1.0  \n",
       "1  2608 COCHRANE DR, CHARLOTTE, NC 28269-4041              1.0  \n",
       "2   113 WINDSTONE DR, COLUMBIA, SC 29212-2148              1.0  \n",
       "3           11258 HGY 64, ARLINGTON, TN 38002              1.0  \n",
       "4   510 SHILOH APT 301, LAREDO, TX 78045-6702              1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_deduped_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7113ce48-f9a2-4b01-bc93-954f963a99cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>claim_numbers</th>\n",
       "      <th>claim_row_count</th>\n",
       "      <th>claim_counts</th>\n",
       "      <th>min_first_date</th>\n",
       "      <th>max_first_date</th>\n",
       "      <th>first_dates</th>\n",
       "      <th>min_last_date</th>\n",
       "      <th>max_last_date</th>\n",
       "      <th>last_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>1M Galaxy</td>\n",
       "      <td>Easy</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>[EHS-481_13-01-2023, EBB-510_13-01-2023, YTV-5...</td>\n",
       "      <td>183.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, ...</td>\n",
       "      <td>2023-01-13 15:28:00</td>\n",
       "      <td>2023-12-15 05:08:00</td>\n",
       "      <td>[2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...</td>\n",
       "      <td>2023-01-13 15:28:00</td>\n",
       "      <td>2023-12-15 05:08:00</td>\n",
       "      <td>[2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29854</th>\n",
       "      <td>1L Galaxy</td>\n",
       "      <td>Easy</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>[ha0223ALL a p, ha0223ALL i p, HJA111102230917...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>2023-02-23 13:28:00</td>\n",
       "      <td>2023-12-14 19:46:00</td>\n",
       "      <td>[2023-02-23 13:28:00, 2023-02-23 13:28:00, 202...</td>\n",
       "      <td>2023-02-23 13:29:00</td>\n",
       "      <td>2023-12-14 19:54:00</td>\n",
       "      <td>[2023-02-23 13:29:00, 2023-02-23 13:29:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137894</th>\n",
       "      <td>123 Hover Street</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30005</td>\n",
       "      <td>[WJ0000000312, WJ0000000313, WJ0000000315, WJ0...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>2023-06-05 07:48:00</td>\n",
       "      <td>2023-07-21 09:41:00</td>\n",
       "      <td>[2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...</td>\n",
       "      <td>2023-06-05 07:48:00</td>\n",
       "      <td>2023-07-21 09:41:00</td>\n",
       "      <td>[2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32934</th>\n",
       "      <td>390 CLAUDIA LN</td>\n",
       "      <td>MIDWAY</td>\n",
       "      <td>GA</td>\n",
       "      <td>31320-3252</td>\n",
       "      <td>[703932376, 722612066, 724730809, 726847882, 7...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>2023-02-28 12:34:00</td>\n",
       "      <td>2023-10-21 07:18:00</td>\n",
       "      <td>[2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...</td>\n",
       "      <td>2023-02-28 12:34:00</td>\n",
       "      <td>2023-10-21 07:18:00</td>\n",
       "      <td>[2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167896</th>\n",
       "      <td>100 Prairie Lane</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>80203</td>\n",
       "      <td>[14141414, 7172023, 7182023, 9012023, 08312023...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[2, 2, 1, 1, 1, 1]</td>\n",
       "      <td>2023-06-30 10:25:00</td>\n",
       "      <td>2023-09-29 14:08:00</td>\n",
       "      <td>[2023-06-30 10:25:00, 2023-07-17 13:57:00, 202...</td>\n",
       "      <td>2023-06-30 12:26:00</td>\n",
       "      <td>2023-09-29 14:08:00</td>\n",
       "      <td>[2023-06-30 12:26:00, 2023-07-17 14:13:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224450</th>\n",
       "      <td>1M GALAXY</td>\n",
       "      <td>EASY</td>\n",
       "      <td>CO</td>\n",
       "      <td>80022</td>\n",
       "      <td>[mikemiller10ed381d1, WANGM12, mikemiller1fe3b...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>2023-09-06 12:17:00</td>\n",
       "      <td>2023-10-18 13:23:00</td>\n",
       "      <td>[2023-09-06 12:17:00, 2023-09-07 11:45:00, 202...</td>\n",
       "      <td>2023-09-06 12:18:00</td>\n",
       "      <td>2023-10-18 13:23:00</td>\n",
       "      <td>[2023-09-06 12:18:00, 2023-09-07 11:45:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56000</th>\n",
       "      <td>810 POWDERHORN DR</td>\n",
       "      <td>ROUND ROCK</td>\n",
       "      <td>TX</td>\n",
       "      <td>78681-2543</td>\n",
       "      <td>[706843117, 710964230, 723246682, 722668589, 7...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>2023-03-18 21:23:00</td>\n",
       "      <td>2023-09-26 13:34:00</td>\n",
       "      <td>[2023-03-18 21:23:00, 2023-04-21 08:50:00, 202...</td>\n",
       "      <td>2023-03-18 21:23:00</td>\n",
       "      <td>2023-09-26 13:34:00</td>\n",
       "      <td>[2023-03-18 21:23:00, 2023-04-21 08:50:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11143</th>\n",
       "      <td>2420 SW 79TH ST</td>\n",
       "      <td>OKLAHOMA CITY</td>\n",
       "      <td>OK</td>\n",
       "      <td>73159-4906</td>\n",
       "      <td>[700083982, 718676281, 718678832, 724228150]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>2023-01-19 14:34:00</td>\n",
       "      <td>2023-08-06 09:42:00</td>\n",
       "      <td>[2023-01-19 14:34:00, 2023-06-22 11:11:00, 202...</td>\n",
       "      <td>2023-01-19 14:34:00</td>\n",
       "      <td>2023-08-06 09:42:00</td>\n",
       "      <td>[2023-01-19 14:34:00, 2023-06-22 11:11:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162742</th>\n",
       "      <td>676 COUNTY ROAD 37</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>TX</td>\n",
       "      <td>75706-7040</td>\n",
       "      <td>[719169682, 725484497, 730138633, 730137262]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>2023-06-27 08:59:00</td>\n",
       "      <td>2023-09-27 13:53:00</td>\n",
       "      <td>[2023-06-27 08:59:00, 2023-08-16 10:06:00, 202...</td>\n",
       "      <td>2023-06-27 09:06:00</td>\n",
       "      <td>2023-09-27 13:56:00</td>\n",
       "      <td>[2023-06-27 09:06:00, 2023-08-16 10:25:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60464</th>\n",
       "      <td>229 OAKDALE AVE</td>\n",
       "      <td>MUNDELEIN</td>\n",
       "      <td>IL</td>\n",
       "      <td>60060-3907</td>\n",
       "      <td>[707423182, 713796596, 732481718, 733854624]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 2]</td>\n",
       "      <td>2023-03-23 15:52:00</td>\n",
       "      <td>2023-10-26 09:11:00</td>\n",
       "      <td>[2023-03-23 15:52:00, 2023-05-13 13:34:00, 202...</td>\n",
       "      <td>2023-03-23 15:52:00</td>\n",
       "      <td>2023-10-27 10:38:00</td>\n",
       "      <td>[2023-03-23 15:52:00, 2023-05-13 13:34:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43548</th>\n",
       "      <td>1536 TIMBER RIDGE DR.</td>\n",
       "      <td>ROCKWALL</td>\n",
       "      <td>TX</td>\n",
       "      <td>75032-7286</td>\n",
       "      <td>[704661107, 713804045, 722253291, 734112360]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>2023-03-08 07:51:00</td>\n",
       "      <td>2023-10-28 14:09:00</td>\n",
       "      <td>[2023-03-08 07:51:00, 2023-05-13 14:07:00, 202...</td>\n",
       "      <td>2023-03-08 07:51:00</td>\n",
       "      <td>2023-10-28 14:09:00</td>\n",
       "      <td>[2023-03-08 07:51:00, 2023-05-13 14:07:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44396</th>\n",
       "      <td>2105 N BRECKENRIDGE ST</td>\n",
       "      <td>ENNIS</td>\n",
       "      <td>TX</td>\n",
       "      <td>75119-1876</td>\n",
       "      <td>[704939981, 707298062, 718679095, 730531357]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>2023-03-08 15:05:00</td>\n",
       "      <td>2023-09-28 07:42:00</td>\n",
       "      <td>[2023-03-08 15:05:00, 2023-03-22 21:07:00, 202...</td>\n",
       "      <td>2023-03-08 15:05:00</td>\n",
       "      <td>2023-09-28 07:42:00</td>\n",
       "      <td>[2023-03-08 15:05:00, 2023-03-22 21:07:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113566</th>\n",
       "      <td>1731 REANEY AVE</td>\n",
       "      <td>SAINT PAUL</td>\n",
       "      <td>MN</td>\n",
       "      <td>55106-4243</td>\n",
       "      <td>[712388735, 717812242, 719361644, 725475487]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2, 2, 3, 2]</td>\n",
       "      <td>2023-05-09 08:30:00</td>\n",
       "      <td>2023-08-15 17:08:00</td>\n",
       "      <td>[2023-05-09 08:30:00, 2023-06-15 16:44:00, 202...</td>\n",
       "      <td>2023-05-09 08:33:00</td>\n",
       "      <td>2023-08-15 17:09:00</td>\n",
       "      <td>[2023-05-09 08:33:00, 2023-06-15 16:46:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122357</th>\n",
       "      <td>8475 MEADOW VALE DR</td>\n",
       "      <td>MEMPHIS</td>\n",
       "      <td>TN</td>\n",
       "      <td>38125-3453</td>\n",
       "      <td>[714294691, 722078011, 722083284, 722083482]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[4, 2, 2, 2]</td>\n",
       "      <td>2023-05-17 15:39:00</td>\n",
       "      <td>2023-07-19 13:15:00</td>\n",
       "      <td>[2023-05-17 15:39:00, 2023-07-19 13:12:00, 202...</td>\n",
       "      <td>2023-07-19 13:14:00</td>\n",
       "      <td>2023-07-22 13:22:00</td>\n",
       "      <td>[2023-07-22 13:22:00, 2023-07-19 13:14:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>2600 S BATTERY ST</td>\n",
       "      <td>LITTLE ROCK</td>\n",
       "      <td>AR</td>\n",
       "      <td>72206-1830</td>\n",
       "      <td>[698808334, 700719131, 711890186, 720517739]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>2023-01-09 17:11:00</td>\n",
       "      <td>2023-07-07 16:24:00</td>\n",
       "      <td>[2023-01-09 17:11:00, 2023-01-25 15:31:00, 202...</td>\n",
       "      <td>2023-01-09 17:55:00</td>\n",
       "      <td>2023-07-07 16:27:00</td>\n",
       "      <td>[2023-01-09 17:55:00, 2023-01-25 15:34:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42283</th>\n",
       "      <td>219 VALLEY VIEW DR</td>\n",
       "      <td>ROBINSON</td>\n",
       "      <td>TX</td>\n",
       "      <td>76706-6159</td>\n",
       "      <td>[704982800, 716388038, 720459098, 730152030]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2, 2, 2, 4]</td>\n",
       "      <td>2023-03-07 11:37:00</td>\n",
       "      <td>2023-09-25 14:37:00</td>\n",
       "      <td>[2023-03-07 11:37:00, 2023-06-05 10:06:00, 202...</td>\n",
       "      <td>2023-03-07 11:39:00</td>\n",
       "      <td>2023-11-16 16:50:00</td>\n",
       "      <td>[2023-03-07 11:39:00, 2023-06-05 10:08:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42641</th>\n",
       "      <td>209 CHARLES DR</td>\n",
       "      <td>LINDALE</td>\n",
       "      <td>TX</td>\n",
       "      <td>75771-3394</td>\n",
       "      <td>[705244804, 713541506, 717640676, 727303489]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>2023-03-07 16:16:00</td>\n",
       "      <td>2023-08-31 09:01:00</td>\n",
       "      <td>[2023-03-07 16:16:00, 2023-05-11 14:30:00, 202...</td>\n",
       "      <td>2023-03-07 16:16:00</td>\n",
       "      <td>2023-08-31 09:01:00</td>\n",
       "      <td>[2023-03-07 16:16:00, 2023-05-11 14:30:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84978</th>\n",
       "      <td>8009 4TH AVE S</td>\n",
       "      <td>BLOOMINGTON</td>\n",
       "      <td>MN</td>\n",
       "      <td>55420-1243</td>\n",
       "      <td>[709618325, 718341134, 720665835, 722706306]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>2023-04-12 17:02:00</td>\n",
       "      <td>2023-07-25 06:44:00</td>\n",
       "      <td>[2023-04-12 17:02:00, 2023-06-21 09:33:00, 202...</td>\n",
       "      <td>2023-04-12 17:02:00</td>\n",
       "      <td>2023-07-25 06:44:00</td>\n",
       "      <td>[2023-04-12 17:02:00, 2023-06-21 09:33:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25779</th>\n",
       "      <td>2616 LOU JOHN ST</td>\n",
       "      <td>AUSTIN</td>\n",
       "      <td>TX</td>\n",
       "      <td>78727-1243</td>\n",
       "      <td>[701933137, 705298478, 712218361, 730059250]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>2023-02-16 08:07:00</td>\n",
       "      <td>2023-09-26 17:44:00</td>\n",
       "      <td>[2023-02-16 08:07:00, 2023-03-06 17:02:00, 202...</td>\n",
       "      <td>2023-02-16 08:07:00</td>\n",
       "      <td>2023-09-26 17:44:00</td>\n",
       "      <td>[2023-02-16 08:07:00, 2023-03-06 17:02:00, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20656</th>\n",
       "      <td>9627 HILLIS</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TX</td>\n",
       "      <td>77078-2824</td>\n",
       "      <td>[702093261, 710179425, 713217636, 718707714]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2, 2, 2, 4]</td>\n",
       "      <td>2023-02-07 10:39:00</td>\n",
       "      <td>2023-06-26 08:49:00</td>\n",
       "      <td>[2023-02-07 10:39:00, 2023-04-14 12:58:00, 202...</td>\n",
       "      <td>2023-02-07 11:27:00</td>\n",
       "      <td>2023-07-24 15:47:00</td>\n",
       "      <td>[2023-02-07 11:27:00, 2023-04-14 13:02:00, 202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        street           city state         zip  \\\n",
       "7701                 1M Galaxy           Easy    CO       80022   \n",
       "29854                1L Galaxy           Easy    CO       80022   \n",
       "137894        123 Hover Street     Alpharetta    GA       30005   \n",
       "32934           390 CLAUDIA LN         MIDWAY    GA  31320-3252   \n",
       "167896        100 Prairie Lane         Denver    CO       80203   \n",
       "224450               1M GALAXY           EASY    CO       80022   \n",
       "56000        810 POWDERHORN DR     ROUND ROCK    TX  78681-2543   \n",
       "11143          2420 SW 79TH ST  OKLAHOMA CITY    OK  73159-4906   \n",
       "162742      676 COUNTY ROAD 37          TYLER    TX  75706-7040   \n",
       "60464          229 OAKDALE AVE      MUNDELEIN    IL  60060-3907   \n",
       "43548    1536 TIMBER RIDGE DR.       ROCKWALL    TX  75032-7286   \n",
       "44396   2105 N BRECKENRIDGE ST          ENNIS    TX  75119-1876   \n",
       "113566         1731 REANEY AVE     SAINT PAUL    MN  55106-4243   \n",
       "122357     8475 MEADOW VALE DR        MEMPHIS    TN  38125-3453   \n",
       "4838         2600 S BATTERY ST    LITTLE ROCK    AR  72206-1830   \n",
       "42283       219 VALLEY VIEW DR       ROBINSON    TX  76706-6159   \n",
       "42641           209 CHARLES DR        LINDALE    TX  75771-3394   \n",
       "84978           8009 4TH AVE S    BLOOMINGTON    MN  55420-1243   \n",
       "25779         2616 LOU JOHN ST         AUSTIN    TX  78727-1243   \n",
       "20656              9627 HILLIS        HOUSTON    TX  77078-2824   \n",
       "\n",
       "                                            claim_numbers  claim_row_count  \\\n",
       "7701    [EHS-481_13-01-2023, EBB-510_13-01-2023, YTV-5...            183.0   \n",
       "29854   [ha0223ALL a p, ha0223ALL i p, HJA111102230917...             23.0   \n",
       "137894  [WJ0000000312, WJ0000000313, WJ0000000315, WJ0...              9.0   \n",
       "32934   [703932376, 722612066, 724730809, 726847882, 7...              6.0   \n",
       "167896  [14141414, 7172023, 7182023, 9012023, 08312023...              6.0   \n",
       "224450  [mikemiller10ed381d1, WANGM12, mikemiller1fe3b...              5.0   \n",
       "56000   [706843117, 710964230, 723246682, 722668589, 7...              5.0   \n",
       "11143        [700083982, 718676281, 718678832, 724228150]              4.0   \n",
       "162742       [719169682, 725484497, 730138633, 730137262]              4.0   \n",
       "60464        [707423182, 713796596, 732481718, 733854624]              4.0   \n",
       "43548        [704661107, 713804045, 722253291, 734112360]              4.0   \n",
       "44396        [704939981, 707298062, 718679095, 730531357]              4.0   \n",
       "113566       [712388735, 717812242, 719361644, 725475487]              4.0   \n",
       "122357       [714294691, 722078011, 722083284, 722083482]              4.0   \n",
       "4838         [698808334, 700719131, 711890186, 720517739]              4.0   \n",
       "42283        [704982800, 716388038, 720459098, 730152030]              4.0   \n",
       "42641        [705244804, 713541506, 717640676, 727303489]              4.0   \n",
       "84978        [709618325, 718341134, 720665835, 722706306]              4.0   \n",
       "25779        [701933137, 705298478, 712218361, 730059250]              4.0   \n",
       "20656        [702093261, 710179425, 713217636, 718707714]              4.0   \n",
       "\n",
       "                                             claim_counts      min_first_date  \\\n",
       "7701    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, ... 2023-01-13 15:28:00   \n",
       "29854   [3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ... 2023-02-23 13:28:00   \n",
       "137894                        [1, 1, 1, 1, 1, 2, 1, 1, 1] 2023-06-05 07:48:00   \n",
       "32934                                  [1, 1, 2, 1, 1, 1] 2023-02-28 12:34:00   \n",
       "167896                                 [2, 2, 1, 1, 1, 1] 2023-06-30 10:25:00   \n",
       "224450                                    [2, 1, 1, 1, 1] 2023-09-06 12:17:00   \n",
       "56000                                     [1, 1, 1, 1, 1] 2023-03-18 21:23:00   \n",
       "11143                                        [1, 1, 1, 1] 2023-01-19 14:34:00   \n",
       "162742                                       [2, 2, 2, 2] 2023-06-27 08:59:00   \n",
       "60464                                        [1, 1, 1, 2] 2023-03-23 15:52:00   \n",
       "43548                                        [1, 1, 1, 1] 2023-03-08 07:51:00   \n",
       "44396                                        [1, 1, 1, 1] 2023-03-08 15:05:00   \n",
       "113566                                       [2, 2, 3, 2] 2023-05-09 08:30:00   \n",
       "122357                                       [4, 2, 2, 2] 2023-05-17 15:39:00   \n",
       "4838                                         [2, 2, 2, 2] 2023-01-09 17:11:00   \n",
       "42283                                        [2, 2, 2, 4] 2023-03-07 11:37:00   \n",
       "42641                                        [1, 1, 1, 1] 2023-03-07 16:16:00   \n",
       "84978                                        [1, 1, 1, 1] 2023-04-12 17:02:00   \n",
       "25779                                        [1, 1, 1, 1] 2023-02-16 08:07:00   \n",
       "20656                                        [2, 2, 2, 4] 2023-02-07 10:39:00   \n",
       "\n",
       "            max_first_date                                        first_dates  \\\n",
       "7701   2023-12-15 05:08:00  [2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...   \n",
       "29854  2023-12-14 19:46:00  [2023-02-23 13:28:00, 2023-02-23 13:28:00, 202...   \n",
       "137894 2023-07-21 09:41:00  [2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...   \n",
       "32934  2023-10-21 07:18:00  [2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...   \n",
       "167896 2023-09-29 14:08:00  [2023-06-30 10:25:00, 2023-07-17 13:57:00, 202...   \n",
       "224450 2023-10-18 13:23:00  [2023-09-06 12:17:00, 2023-09-07 11:45:00, 202...   \n",
       "56000  2023-09-26 13:34:00  [2023-03-18 21:23:00, 2023-04-21 08:50:00, 202...   \n",
       "11143  2023-08-06 09:42:00  [2023-01-19 14:34:00, 2023-06-22 11:11:00, 202...   \n",
       "162742 2023-09-27 13:53:00  [2023-06-27 08:59:00, 2023-08-16 10:06:00, 202...   \n",
       "60464  2023-10-26 09:11:00  [2023-03-23 15:52:00, 2023-05-13 13:34:00, 202...   \n",
       "43548  2023-10-28 14:09:00  [2023-03-08 07:51:00, 2023-05-13 14:07:00, 202...   \n",
       "44396  2023-09-28 07:42:00  [2023-03-08 15:05:00, 2023-03-22 21:07:00, 202...   \n",
       "113566 2023-08-15 17:08:00  [2023-05-09 08:30:00, 2023-06-15 16:44:00, 202...   \n",
       "122357 2023-07-19 13:15:00  [2023-05-17 15:39:00, 2023-07-19 13:12:00, 202...   \n",
       "4838   2023-07-07 16:24:00  [2023-01-09 17:11:00, 2023-01-25 15:31:00, 202...   \n",
       "42283  2023-09-25 14:37:00  [2023-03-07 11:37:00, 2023-06-05 10:06:00, 202...   \n",
       "42641  2023-08-31 09:01:00  [2023-03-07 16:16:00, 2023-05-11 14:30:00, 202...   \n",
       "84978  2023-07-25 06:44:00  [2023-04-12 17:02:00, 2023-06-21 09:33:00, 202...   \n",
       "25779  2023-09-26 17:44:00  [2023-02-16 08:07:00, 2023-03-06 17:02:00, 202...   \n",
       "20656  2023-06-26 08:49:00  [2023-02-07 10:39:00, 2023-04-14 12:58:00, 202...   \n",
       "\n",
       "             min_last_date       max_last_date  \\\n",
       "7701   2023-01-13 15:28:00 2023-12-15 05:08:00   \n",
       "29854  2023-02-23 13:29:00 2023-12-14 19:54:00   \n",
       "137894 2023-06-05 07:48:00 2023-07-21 09:41:00   \n",
       "32934  2023-02-28 12:34:00 2023-10-21 07:18:00   \n",
       "167896 2023-06-30 12:26:00 2023-09-29 14:08:00   \n",
       "224450 2023-09-06 12:18:00 2023-10-18 13:23:00   \n",
       "56000  2023-03-18 21:23:00 2023-09-26 13:34:00   \n",
       "11143  2023-01-19 14:34:00 2023-08-06 09:42:00   \n",
       "162742 2023-06-27 09:06:00 2023-09-27 13:56:00   \n",
       "60464  2023-03-23 15:52:00 2023-10-27 10:38:00   \n",
       "43548  2023-03-08 07:51:00 2023-10-28 14:09:00   \n",
       "44396  2023-03-08 15:05:00 2023-09-28 07:42:00   \n",
       "113566 2023-05-09 08:33:00 2023-08-15 17:09:00   \n",
       "122357 2023-07-19 13:14:00 2023-07-22 13:22:00   \n",
       "4838   2023-01-09 17:55:00 2023-07-07 16:27:00   \n",
       "42283  2023-03-07 11:39:00 2023-11-16 16:50:00   \n",
       "42641  2023-03-07 16:16:00 2023-08-31 09:01:00   \n",
       "84978  2023-04-12 17:02:00 2023-07-25 06:44:00   \n",
       "25779  2023-02-16 08:07:00 2023-09-26 17:44:00   \n",
       "20656  2023-02-07 11:27:00 2023-07-24 15:47:00   \n",
       "\n",
       "                                               last_dates  \n",
       "7701    [2023-01-13 15:28:00, 2023-01-13 19:29:00, 202...  \n",
       "29854   [2023-02-23 13:29:00, 2023-02-23 13:29:00, 202...  \n",
       "137894  [2023-06-05 07:48:00, 2023-06-06 05:07:00, 202...  \n",
       "32934   [2023-02-28 12:34:00, 2023-07-24 15:09:00, 202...  \n",
       "167896  [2023-06-30 12:26:00, 2023-07-17 14:13:00, 202...  \n",
       "224450  [2023-09-06 12:18:00, 2023-09-07 11:45:00, 202...  \n",
       "56000   [2023-03-18 21:23:00, 2023-04-21 08:50:00, 202...  \n",
       "11143   [2023-01-19 14:34:00, 2023-06-22 11:11:00, 202...  \n",
       "162742  [2023-06-27 09:06:00, 2023-08-16 10:25:00, 202...  \n",
       "60464   [2023-03-23 15:52:00, 2023-05-13 13:34:00, 202...  \n",
       "43548   [2023-03-08 07:51:00, 2023-05-13 14:07:00, 202...  \n",
       "44396   [2023-03-08 15:05:00, 2023-03-22 21:07:00, 202...  \n",
       "113566  [2023-05-09 08:33:00, 2023-06-15 16:46:00, 202...  \n",
       "122357  [2023-07-22 13:22:00, 2023-07-19 13:14:00, 202...  \n",
       "4838    [2023-01-09 17:55:00, 2023-01-25 15:34:00, 202...  \n",
       "42283   [2023-03-07 11:39:00, 2023-06-05 10:08:00, 202...  \n",
       "42641   [2023-03-07 16:16:00, 2023-05-11 14:30:00, 202...  \n",
       "84978   [2023-04-12 17:02:00, 2023-06-21 09:33:00, 202...  \n",
       "25779   [2023-02-16 08:07:00, 2023-03-06 17:02:00, 202...  \n",
       "20656   [2023-02-07 11:27:00, 2023-04-14 13:02:00, 202...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_deduped.sort_values('claim_row_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8262d-3ecc-4379-8fd4-9c63059f5511",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Find Underwriting with calims in 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1bd5332-d069-4b12-9614-f4528fc31b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import usaddress\n",
    "\n",
    "def find_column_name(df, possible_names):\n",
    "    \"\"\"\n",
    "    Finds the first column name in the DataFrame that matches any of the possible names.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to search in.\n",
    "    - possible_names: List of possible names (in lowercase) for the column.\n",
    "    \n",
    "    Returns:\n",
    "    - The name of the first matching column, or None if no match is found.\n",
    "    \"\"\"\n",
    "    column_names = df.columns.str.lower()  # Convert all column names to lowercase for case-insensitive matching\n",
    "    for possible_name in possible_names:\n",
    "        for column in column_names:\n",
    "            if possible_name in column:\n",
    "                # Return the original column name\n",
    "                return df.columns[column_names == column][0]\n",
    "    return None\n",
    "\n",
    "def standardize_zip(zip_code):\n",
    "    # Check for NaN values to avoid type errors\n",
    "    if pd.isnull(zip_code):\n",
    "        return \"\"\n",
    "    else:\n",
    "        # Extract the first 5 digits from the zip code\n",
    "        match = re.search(r'\\d{1,5}', str(zip_code))\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "        else:\n",
    "            # Return NaN if no valid 5-digit sequence is found\n",
    "            return \"\"\n",
    "\n",
    "def standardize_address(df):\n",
    "    \"\"\"\n",
    "    Dynamically identifies address component columns and combines them into a standardized address.\n",
    "    \n",
    "    Parameters:\n",
    "    - row: Row of the DataFrame for which to generate the standardized address.\n",
    "    - df: DataFrame containing the address information.\n",
    "    \n",
    "    Returns:\n",
    "    - The standardized address as a string.\n",
    "    \"\"\"\n",
    "    # Dynamically find column names for each address component\n",
    "    street_col = find_column_name(df, ['street', 'st'])\n",
    "    city_col = find_column_name(df, ['city'])\n",
    "    state_col = find_column_name(df, ['state', 'st'])\n",
    "    zip_col = find_column_name(df, ['zip', 'postal', 'postcode'])\n",
    "    \n",
    "    # Ensure zip code is in the correct format before standardizing the address\n",
    "    df['zip_5_digit'] = df[zip_col].apply(standardize_zip)\n",
    "    \n",
    "    # Combine address components and standardize\n",
    "    df['full_address'] = df[street_col].astype(str) + \", \" + df[city_col].astype(str) + \", \" + df[state_col].astype(str) + \" \" + df['zip_5_digit'].astype(str)\n",
    "    df['full_address'] = df['full_address'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "    df.drop('zip_5_digit', axis=1, inplace=True)\n",
    "    return df\n",
    "# def parse_and_standardize_address(street, city, state, zip_code):\n",
    "#     \"\"\"\n",
    "#     Use the usaddress module to parse and standardize an address.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - street, city, state, zip_code: Address components.\n",
    "    \n",
    "#     Returns:\n",
    "#     - A standardized address string.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Combine address components\n",
    "#         address = f\"{street}, {city}, {state} {zip_code}\"\n",
    "#         # Parse address using usaddress\n",
    "#         parsed_address = usaddress.parse(address)\n",
    "#         # Reconstruct the address from parsed components (customize as needed)\n",
    "#         standardized_address = \" \".join([part[0] for part in parsed_address])\n",
    "#         return standardized_address\n",
    "#     except usaddress.RepeatedLabelError as e:\n",
    "#         print(f\"Error parsing address: {e}\")\n",
    "#         return address  # Return original address on error\n",
    "\n",
    "# def standardize_address(df):\n",
    "#     \"\"\"\n",
    "#     Updates the DataFrame to include a column for standardized addresses.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: DataFrame containing the address information.\n",
    "    \n",
    "#     Returns:\n",
    "#     - DataFrame with an additional column for the standardized address.\n",
    "#     \"\"\"\n",
    "#     # Dynamically find column names for each address component\n",
    "#     street_col = find_column_name(df, ['street', 'st'])\n",
    "#     city_col = find_column_name(df, ['city'])\n",
    "#     state_col = find_column_name(df, ['state', 'st'])\n",
    "#     zip_col = find_column_name(df, ['zip', 'postal', 'postcode'])\n",
    "    \n",
    "#     # Ensure zip code is in the correct format before standardizing the address\n",
    "#     df['zip_5_digit'] = df[zip_col].apply(standardize_zip)\n",
    "    \n",
    "#     # Apply parsing and standardization of addresses\n",
    "#     df['standardized_address'] = df.apply(lambda row: parse_and_standardize_address(row[street_col], row[city_col], row[state_col], row['zip_5_digit']), axis=1)\n",
    "    \n",
    "#     # Optionally, you can drop the temporary 'zip_5_digit' column if you don't need it\n",
    "#     df.drop('zip_5_digit', axis=1, inplace=True)\n",
    "    \n",
    "#     return df\n",
    "def add_claim_info(df_a, df_b):\n",
    "    # Standardize addresses in both DataFrames\n",
    "    df_a = standardize_address(df_a)\n",
    "    df_b = standardize_address(df_b)\n",
    "    df_a['full_address_lower'] = df_a['full_address'].str.lower()\n",
    "    df_b['full_address_lower'] = df_b['full_address'].str.lower()\n",
    "    \n",
    "    # Merge df_a with relevant columns from df_b based on standardized address\n",
    "    merged_df = pd.merge(df_a, df_b[['full_address_lower', 'claim_number', 'claim_row_count', 'claim_count', 'first_date', 'last_date']], \n",
    "                         on='full_address_lower', how='left')\n",
    "    \n",
    "    # Add 'claim_exists' column: 1 if there's a match, 0 otherwise\n",
    "    merged_df['claim_exists'] = merged_df['claim_number'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Drop the 'std_address' column if you don't need it anymore\n",
    "    df_a.drop('full_address_lower', axis=1, inplace=True)\n",
    "    df_b.drop('full_address_lower', axis=1, inplace=True)\n",
    "    merged_df.drop('full_address_lower', axis=1, inplace=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# # Assume df_a and df_b are already defined and loaded with your data\n",
    "# # Call the function with your DataFrames\n",
    "# df_a_updated = add_claim_info(df_a, df_b)\n",
    "\n",
    "# # Display the updated DataFrame\n",
    "# print(df_a_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66a5c9eb-2f0b-4981-aa86-8c618c21b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using full_address\n",
    "df_claims_UW = add_claim_info(df_UW, df_claims_deduped_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92580b83-1571-4a08-99a9-b148ba7d63d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98435, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_UW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bfb3d94-3807-4848-ae70-b9fdb622d983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98433"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_UW['full_address'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c493745-3dfe-49f6-b39d-e51af19ead56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98435"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_claims_UW['full_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0c70ca8-8499-4873-9ba9-db4b9266a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claim_exists\n",
       "0    95462\n",
       "1     2973\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_UW['claim_exists'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32146855-ee6d-45d1-b3a9-6b0e2643a3be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6f3e9-e961-402d-9cd0-8f11acbf366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of claims:\", sum(df_claims_UW.claim_exists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cb7c2-0f0c-4130-80c0-45d8f722310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims_UW.loc[df_claims_UW.claim_exists == 1, 'claim_row_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519e42b-43b7-4931-9d78-7af806031dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_addresses = df_claims_UW.loc[\n",
    "    (df_claims_UW['claim_exists'] == 1) & (df_claims_UW['claim_row_count'] > 2), \n",
    "    'full_address'\n",
    "].str.lower().tolist()\n",
    "\n",
    "\n",
    "df_claims['meets_criteria'] = df_claims['full_address'].apply(\n",
    "    lambda address: any(\n",
    "        filter_addr in address.lower() for filter_addr in filtered_addresses\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e744216-b532-4043-8b89-0a882bfebe12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_claims[df_claims['meets_criteria']].sort_values('full_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93079db1-a31e-4b35-931e-2f1cb58ced5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims_deduped_simple[df_claims_deduped_simple['full_address'] == \"11502 E JAYHAWK ST, HOUSTON, TX 77044\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560cb15-54b9-4c31-8bf6-b5e86b62122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims_UW.loc[df_claims_UW.claim_exists == 1, 'claim_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35cf66-e433-4f70-9cc8-135c78852e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of claims on unique address:\", df_claims_UW.loc[df_claims_UW.claim_exists == 1, 'full_address'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87114a0b-b017-446a-9767-c0fa0c2ec2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims_UW_dedup = df_claims_UW.drop_duplicates(subset=['full_address'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03bd0845-4b2e-4167-a458-098260edcb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2972"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_claims_UW_dedup.claim_exists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f33fc-5d67-488c-b4c2-33b6df4a5a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c1bf4d3-0a49-4a58-a819-d5af1eef8570",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PULL RCI DATA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da47b8b-50f7-4b58-8294-9c9436e80185",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = df_claims_UW.loc[df_claims_UW.claim_exists == 1, 'full_address'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eb06565-b9ec-4898-a8be-3701ebc4c16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2972"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727e3b5-c305-4703-a8c7-e1d5bf6c9435",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## UAT - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607f473-f049-4297-b9bc-04351c93f1af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# multiprocess\n",
    "# rci = RoofConditionInsights(\n",
    "#     env=\"PRD\",\n",
    "#     api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "#     api_companyid=\"3168675050\",\n",
    "#     username=\"all@vod.com\",\n",
    "#     password=\"myriadvod123456\",\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "st = time.time()\n",
    "df_roof_condition_insights = rci.process_multiple_addresses(addresses[:5], generate_pdf=False, save_json=True)\n",
    "et = time.time()\n",
    "print('Processing time', et - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496f8ff-18b3-4c73-8627-1f03a9c632eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PROD - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d410b6-704d-489d-9ae8-ddd12ed56a87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rci = RoofConditionInsights(\n",
    "    env=\"PRD\",\n",
    "    api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "    api_companyid=\"3168675050\",\n",
    "    username=\"all@vod.com\",\n",
    "    password=\"myriadvod123456\"\n",
    ")\n",
    "\n",
    "st = time.time()\n",
    "df_roof_condition_insights = rci.process_multiple_addresses(addresses[:100], generate_pdf=False, save_json=True)\n",
    "et = time.time()\n",
    "print('Processing time', et - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d64f0be-ca19-48a5-b909-f9abb870b4fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PULL UW W. CLAIM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295d4933-bff1-4638-9e8f-6a9a91479da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_addresses = df_claims_UW.loc[df_claims_UW.claim_exists == 1, 'full_address'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60bef56d-e026-4e5d-bb54-adc528c464c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2972"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claim_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54c08812-ee53-4080-a3cc-65817371372c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rci = RoofConditionInsights(\n",
    "#     env=\"PRD\",\n",
    "#     api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "#     api_companyid=\"3168675050\",\n",
    "#     username=\"all@vod.com\",\n",
    "#     password=\"myriadvod123456\",\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# st = time.time()\n",
    "# # df_rci_uw_w_claims = rci.process_multiple_addresses(claim_addresses, generate_pdf=False, save_json=True)\n",
    "# df_rci_uw_w_claims = rci.process_multiple_addresses(claim_addresses, \n",
    "#                                generate_pdf=False, \n",
    "#                                save_json=False, \n",
    "#                                start_index=2190, \n",
    "#                                process_method='parallel', \n",
    "#                                max_workers=5)\n",
    "# et = time.time()\n",
    "# print('Processing time', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cee7f4cb-3b1a-4bd6-b588-583551066e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_claims = pd.read_csv('../data/datasets/output/claim_data_2023_UW_Q4_allstate_prod_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccecc2fd-e65c-4bd1-8df7-eee8ec6f5b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_status_code\n",
       "200    2338\n",
       "204     633\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_claims.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77804458-b249-4f63-a26d-7dda476f1728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2971, 49)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9177204-c57b-4f55-ad47-0d142cdd969f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2971"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_claims.address.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d91dbc8-4ccc-4e7a-9e8b-78ddd27238db",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_address = df_rci_uw_w_claims.loc[df_rci_uw_w_claims['run_completed'], 'address'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "616799e7-a722-4d34-941b-e3f7cdc62abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2338"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10749b74-c31e-4b22-82b3-fdc2d69d8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Addresses: 78.67\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieved Addresses:\", round(100 * len(retrieved_address) / len(claim_addresses), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecdd02c5-e99f-41ef-8415-12435a99204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed_addresses = df_rci_uw_w_claims.loc[df_rci_uw_w_claims.run_completed == False, 'address'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fd886b8-9c3c-421b-b38d-2a645ced3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rci_uw_w_claims_failed_addresses = rci.process_multiple_addresses(failed_addresses, \n",
    "#                                generate_pdf=False, \n",
    "#                                save_json=False, \n",
    "#                                start_index=0, \n",
    "#                                process_method='parallel', \n",
    "#                                max_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d821fe55-1e43-41c7-9756-c9d0a4f3c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read__csv('../data/datasets/output/claim_data_2023_UW_Q4_allstate_prod.csv', index=False)\n",
    "# df_failed_addresses = pd.read_csv('../data/datasets/output/rci_data_final_20240401_2042.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52f6c34e-74d1-4c69-a3c2-b2eda4efd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_failed_addresses.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04189d72-017f-496c-9253-a98a50e030f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df_rci_uw_w_claims\n",
    "# df2 = df_failed_addresses\n",
    "# concatenated_df = pd.concat([df1, df2], ignore_index=True)\n",
    "# concatenated_df.sort_values(by='run_status_code', ascending=True, inplace=True)\n",
    "# deduplicated_df = concatenated_df.drop_duplicates(subset='address')\n",
    "# deduplicated_df.reset_index(drop=True, inplace=True)\n",
    "# deduplicated_df.to_csv('../data/datasets/output/claim_data_2023_UW_Q4_allstate_prod_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa8f54b3-e64b-4bba-82f6-cc2cba8b067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicated_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c55bd3e7-e0db-4bc1-80cd-d821db1134aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicated_df.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ee542-1d88-4725-b896-8aeb2da7b7a3",
   "metadata": {},
   "source": [
    "## PULL UW WO. CLAIM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34e7ddd3-cbcc-4321-8432-99a78b9a0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered df --> claim data retrived form api + all non-claim data\n",
    "condition_1 = df_claims_UW['full_address'].isin(retrieved_address) & (df_claims_UW['claim_exists'] == True)\n",
    "condition_2 = df_claims_UW['claim_exists'] == False\n",
    "combined_condition = condition_1 | condition_2\n",
    "filtered_df = df_claims_UW[combined_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb529d8c-1684-487c-b0a1-af5930f5ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_group(group, false_to_true_ratio=3):\n",
    "#     n_true = int(group['claim_exists'].sum())\n",
    "#     n_false = len(group) - n_true  # Total number of false claims in the group\n",
    "#     n_false_required = n_true * false_to_true_ratio\n",
    "    \n",
    "#     shortfall = max(0, n_false_required - n_false)  # Calculate shortfall in the False claims\n",
    "#     sampled_false = group[group['claim_exists'] == False].sample(n=min(n_false, n_false_required), replace=False)\n",
    "#     sampled_true = group[group['claim_exists'] == True]\n",
    "    \n",
    "#     return pd.concat([sampled_false, sampled_true]), shortfall\n",
    "\n",
    "# zip_groups = filtered_df.groupby('UW_ZIP')\n",
    "# shortfalls = {}\n",
    "# zip_sampled_list = []\n",
    "\n",
    "# for zip_code, group in zip_groups:\n",
    "#     sampled_group, shortfall = sample_group(group)\n",
    "#     zip_sampled_list.append(sampled_group)\n",
    "#     if shortfall > 0:\n",
    "#         shortfalls[zip_code] = shortfall\n",
    "\n",
    "# zip_sampled = pd.concat(zip_sampled_list).reset_index(drop=True)\n",
    "\n",
    "# # Fill the shortfalls from the corresponding UW_STATE\n",
    "# zip_to_state = filtered_df.drop_duplicates('UW_ZIP')[['UW_ZIP', 'UW_STATE']].set_index('UW_ZIP')['UW_STATE'].to_dict()\n",
    "\n",
    "# state_sampled_list = []\n",
    "# for zip_code, shortfall in shortfalls.items():\n",
    "#     state = zip_to_state[zip_code]\n",
    "#     state_group = filtered_df[(filtered_df['UW_STATE'] == state) & (filtered_df['claim_exists'] == False)]\n",
    "#     # Sample additional false claims to meet the shortfall\n",
    "#     additional_sample = state_group.sample(n=min(shortfall, len(state_group)), replace=False)\n",
    "#     state_sampled_list.append(additional_sample)\n",
    "\n",
    "# state_sampled = pd.concat(state_sampled_list).reset_index(drop=True)\n",
    "# final_sampled_df = pd.concat([zip_sampled, state_sampled]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fda0bdd-2b23-4610-a727-6ffdbcfebfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_data(df, method='zip', false_to_true_ratio=3):\n",
    "#     if method == 'zip':\n",
    "#         groups = df.groupby('UW_ZIP')\n",
    "#         shortfalls = {}\n",
    "#         sampled_list = []\n",
    "\n",
    "#         for zip_code, group in groups:\n",
    "#             sampled_group, shortfall = sample_group(group, false_to_true_ratio)\n",
    "#             sampled_list.append(sampled_group)\n",
    "#             if shortfall > 0:\n",
    "#                 shortfalls[zip_code] = shortfall\n",
    "\n",
    "#         sampled = pd.concat(sampled_list).reset_index(drop=True)\n",
    "\n",
    "#         # Fill the shortfalls from the corresponding UW_STATE\n",
    "#         zip_to_state = df.drop_duplicates('UW_ZIP')[['UW_ZIP', 'UW_STATE']].set_index('UW_ZIP')['UW_STATE'].to_dict()\n",
    "\n",
    "#         additional_sample_list = []\n",
    "#         for zip_code, shortfall in shortfalls.items():\n",
    "#             state = zip_to_state.get(zip_code)\n",
    "#             if state:\n",
    "#                 already_selected = sampled[sampled['UW_STATE'] == state]\n",
    "#                 state_group = df[(df['UW_STATE'] == state) & (df['claim_exists'] == False) & (~df.index.isin(already_selected.index))]           \n",
    "#                 additional_sample = state_group.sample(n=min(shortfall, len(state_group)), replace=False)\n",
    "#                 additional_sample_list.append(additional_sample)\n",
    "#             else:\n",
    "#                 print(f\"No corresponding state found for zip code {zip_code}\")\n",
    "\n",
    "#         additional_sampled = pd.concat(additional_sample_list).reset_index(drop=True)\n",
    "#         final_sampled_df = pd.concat([sampled, additional_sampled]).drop_duplicates()\n",
    "        \n",
    "#     elif method == 'state':\n",
    "#         groups = df.groupby('UW_STATE')\n",
    "#         shortfalls = {}\n",
    "#         sampled_list = []\n",
    "\n",
    "#         for state, group in groups:\n",
    "#             sampled_group, shortfall = sample_group(group, false_to_true_ratio)\n",
    "#             sampled_list.append(sampled_group)\n",
    "#             if shortfall > 0:\n",
    "#                 shortfalls[state] = shortfall\n",
    "\n",
    "#         sampled = pd.concat(sampled_list).reset_index(drop=True)\n",
    "\n",
    "#         # Fill the shortfalls from the national level only if there are shortfalls for any states\n",
    "#         if shortfalls:\n",
    "#             national_group = df[df['claim_exists'] == False]\n",
    "#             additional_sample_list = []\n",
    "#             for state, shortfall in shortfalls.items():\n",
    "#                 already_selected = sampled[sampled['UW_STATE'] == state]\n",
    "#                 state_group = df[(df['UW_STATE'] == state) & (df['claim_exists'] == False) & (~df.index.isin(already_selected.index))]\n",
    "#                 additional_sample = national_group.sample(n=min(shortfall, len(national_group)), replace=False)\n",
    "#                 additional_sample_list.append(additional_sample)\n",
    "\n",
    "#             additional_sampled = pd.concat(additional_sample_list).reset_index(drop=True)\n",
    "#             final_sampled_df = pd.concat([sampled, additional_sampled]).drop_duplicates()\n",
    "#         else:\n",
    "#             final_sampled_df = sampled  # No shortfalls for any states, return the sampled DataFrame\n",
    "\n",
    "#     elif method == 'national':\n",
    "#         false_group = df[df['claim_exists'] == False]\n",
    "#         true_group = df[df['claim_exists'] == True]\n",
    "#         n_true = len(true_group)\n",
    "#         n_false = len(false_group)\n",
    "#         n_false_required = n_true * false_to_true_ratio\n",
    "#         sampled_false = false_group.sample(n=min(n_false, n_false_required), replace=False)\n",
    "#         final_sampled_df = pd.concat([sampled_false, true_group])\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid sampling method. Choose from 'zip', 'state', or 'national'.\")\n",
    "\n",
    "#     return final_sampled_df\n",
    "\n",
    "# final_sampled_df = sample_data(filtered_df, method='national', false_to_true_ratio=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24098a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, method='zip', false_to_true_ratio=3):\n",
    "    if method == 'zip':\n",
    "        groups = df.groupby('UW_ZIP')\n",
    "        shortfalls = {}\n",
    "        sampled_list = []\n",
    "\n",
    "        for zip_code, group in groups:\n",
    "            sampled_group, shortfall = sample_group(group, false_to_true_ratio)\n",
    "            sampled_list.append(sampled_group)\n",
    "            if shortfall > 0:\n",
    "                shortfalls[zip_code] = shortfall\n",
    "\n",
    "        sampled = pd.concat(sampled_list).reset_index(drop=True)\n",
    "\n",
    "        # Fill the shortfalls from the corresponding UW_STATE\n",
    "        zip_to_state = df.drop_duplicates('UW_ZIP')[['UW_ZIP', 'UW_STATE']].set_index('UW_ZIP')['UW_STATE'].to_dict()\n",
    "\n",
    "        additional_sample_list = []\n",
    "        for zip_code, shortfall in shortfalls.items():\n",
    "            state = zip_to_state.get(zip_code)\n",
    "            if state:\n",
    "                already_selected = sampled[sampled['UW_STATE'] == state]\n",
    "                state_group = df[(df['UW_STATE'] == state) & (df['claim_exists'] == False) & (~df.index.isin(already_selected.index))]           \n",
    "                additional_sample = state_group.sample(n=min(shortfall, len(state_group)), replace=False)\n",
    "                additional_sample_list.append(additional_sample)\n",
    "            else:\n",
    "                print(f\"No corresponding state found for zip code {zip_code}\")\n",
    "\n",
    "        additional_sampled = pd.concat(additional_sample_list).reset_index(drop=True)\n",
    "        final_sampled_df = pd.concat([sampled, additional_sampled]).drop_duplicates()\n",
    "        \n",
    "    elif method == 'state':\n",
    "        groups = df.groupby('UW_STATE')\n",
    "        shortfalls = {}\n",
    "        sampled_list = []\n",
    "\n",
    "        for state, group in groups:\n",
    "            sampled_group, shortfall = sample_group(group, false_to_true_ratio)\n",
    "            sampled_list.append(sampled_group)\n",
    "            if shortfall > 0:\n",
    "                shortfalls[state] = shortfall\n",
    "\n",
    "        sampled = pd.concat(sampled_list).reset_index(drop=True)\n",
    "\n",
    "        # Fill the shortfalls from the national level only if there are shortfalls for any states\n",
    "        if shortfalls:\n",
    "            national_group = df[df['claim_exists'] == False]\n",
    "            additional_sample_list = []\n",
    "            for state, shortfall in shortfalls.items():\n",
    "                already_selected = sampled[sampled['UW_STATE'] == state]\n",
    "                state_group = df[(df['UW_STATE'] == state) & (df['claim_exists'] == False) & (~df.index.isin(already_selected.index))]\n",
    "                additional_sample = national_group.sample(n=min(shortfall, len(national_group)), replace=False)\n",
    "                additional_sample_list.append(additional_sample)\n",
    "\n",
    "            additional_sampled = pd.concat(additional_sample_list).reset_index(drop=True)\n",
    "            final_sampled_df = pd.concat([sampled, additional_sampled]).drop_duplicates()\n",
    "        else:\n",
    "            final_sampled_df = sampled  # No shortfalls for any states, return the sampled DataFrame\n",
    "\n",
    "    elif method == 'national':\n",
    "        false_group = df[df['claim_exists'] == False]\n",
    "        true_group = df[df['claim_exists'] == True]\n",
    "        n_true = len(true_group)\n",
    "        n_false = len(false_group)\n",
    "        n_false_required = n_true * false_to_true_ratio\n",
    "        sampled_false = false_group.sample(n=min(n_false, n_false_required), replace=False)\n",
    "        final_sampled_df = pd.concat([sampled_false, true_group])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sampling method. Choose from 'zip', 'state', or 'national'.\")\n",
    "\n",
    "    return final_sampled_df\n",
    "\n",
    "final_sampled_df = sample_data(filtered_df, method='national', false_to_true_ratio=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2f81ae6-4d7d-40e0-b68d-23cd2e1f907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14034, 13)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "587062aa-049f-4ad0-9ea5-82d4b8b72df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sampled_df.to_csv('../data/datasets/output/sampled_data_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201469f7-f1d5-4dc2-a01b-bb07617a88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new start\n",
    "final_sampled_df = pd.read_csv('../data/datasets/output/sampled_data_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db1ab33-72f8-4f82-8fd1-b0c5b27e8fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_claim_addresses = final_sampled_df.loc[final_sampled_df.claim_exists == 0, 'full_address'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c305075-e302-41d1-9c98-dd50c88c04e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11695"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_claim_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcca2d36-c37f-4d03-8b7a-4add4a6b61a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "claim_addresses = final_sampled_df.loc[final_sampled_df.claim_exists == 1, 'full_address'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4534a6-d743-4a1d-a3f3-ada825ab372f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2339"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claim_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ea6c34-9b64-44a6-a9ca-10de566af1ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token is retrieved with status code 200.\n",
      "\n",
      "\n",
      "---\n",
      "Starting new run for 11695 addresses from index 0 using parallel processing...\n",
      "Created folder: /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_0_to_500_20240403_0053.parquet\n",
      "Chunk (index) [0:500] Processed - Success: 62.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_500_to_1000_20240403_0101.parquet\n",
      "Chunk (index) [500:1000] Processed - Success: 67.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_1000_to_1500_20240403_0110.parquet\n",
      "Chunk (index) [1000:1500] Processed - Success: 69.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_1500_to_2000_20240403_0119.parquet\n",
      "Chunk (index) [1500:2000] Processed - Success: 70.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_2000_to_2500_20240403_0127.parquet\n",
      "Chunk (index) [2000:2500] Processed - Success: 67.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_2500_to_3000_20240403_0136.parquet\n",
      "Chunk (index) [2500:3000] Processed - Success: 68.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_3000_to_3500_20240403_0144.parquet\n",
      "Chunk (index) [3000:3500] Processed - Success: 70.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_3500_to_4000_20240403_0153.parquet\n",
      "Chunk (index) [3500:4000] Processed - Success: 68.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_4000_to_4500_20240403_0201.parquet\n",
      "Chunk (index) [4000:4500] Processed - Success: 68.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_4500_to_5000_20240403_0210.parquet\n",
      "Chunk (index) [4500:5000] Processed - Success: 69.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_5000_to_5500_20240403_0218.parquet\n",
      "Chunk (index) [5000:5500] Processed - Success: 70.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_5500_to_6000_20240403_0227.parquet\n",
      "Chunk (index) [5500:6000] Processed - Success: 70.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_6000_to_6500_20240403_0235.parquet\n",
      "Chunk (index) [6000:6500] Processed - Success: 69.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_6500_to_7000_20240403_0244.parquet\n",
      "Chunk (index) [6500:7000] Processed - Success: 68.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_7000_to_7500_20240403_0252.parquet\n",
      "Chunk (index) [7000:7500] Processed - Success: 70.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_7500_to_8000_20240403_0301.parquet\n",
      "Chunk (index) [7500:8000] Processed - Success: 67.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_8000_to_8500_20240403_0309.parquet\n",
      "Chunk (index) [8000:8500] Processed - Success: 59.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_8500_to_9000_20240403_0318.parquet\n",
      "Chunk (index) [8500:9000] Processed - Success: 60.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_9000_to_9500_20240403_0326.parquet\n",
      "Chunk (index) [9000:9500] Processed - Success: 64.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_9500_to_10000_20240403_0335.parquet\n",
      "Chunk (index) [9500:10000] Processed - Success: 67.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_10000_to_10500_20240403_0343.parquet\n",
      "Chunk (index) [10000:10500] Processed - Success: 61.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_10500_to_11000_20240403_0352.parquet\n",
      "Chunk (index) [10500:11000] Processed - Success: 62.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_11000_to_11500_20240403_0400.parquet\n",
      "Chunk (index) [11000:11500] Processed - Success: 63.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/roof_condition_insights.py:587: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_chunk = pd.concat(chunk_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/Checkpoints_20240403_0044/checkpoint_11500_to_12000_20240403_0403.parquet\n",
      "Chunk (index) [11500:11695] Processed - Success: 69.74%\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Merged dataframe saved to /home/jupyter/majid/roof-condition-insights/data/datasets/output/merged_Checkpoints_20240403_0044.parquet\n",
      "Finished running for 11695 addresses using parallel processing.\n",
      "Processing time 12037.640541791916\n"
     ]
    }
   ],
   "source": [
    "rci = RoofConditionInsights(\n",
    "    env=\"PRD\",\n",
    "    api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "    api_companyid=\"3168675050\",\n",
    "    username=\"all@vod.com\",\n",
    "    password=\"myriadvod123456\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "st = time.time()\n",
    "# df_rci_uw_wo_claims = rci.process_multiple_addresses(no_claim_addresses, generate_pdf=False, save_json=Flase)\n",
    "df_rci_uw_wo_claims = rci.process_multiple_addresses(no_claim_addresses, \n",
    "                               generate_pdf=False, \n",
    "                               save_json=False, \n",
    "                               start_index=0, \n",
    "                               process_method='parallel', \n",
    "                               max_workers=5,\n",
    "                               chunk_size=500)\n",
    "et = time.time()\n",
    "print('Processing time', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a54cc1-a797-4d46-a5e9-2a31812f639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_wo_claims = pd.read_parquet(\"../data/datasets/output/Checkpoints_20240403_0044/checkpoint_11500_to_12000_20240403_0403.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96374e59-1b9d-4830-9f87-a4e6ff36c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'Checkpoints_20240402_2144'\n",
    "data_dir = '../data'\n",
    "folder_path = os.path.join(data_dir, 'datasets/output', folder_name)\n",
    "\n",
    "# # Create the folder if it doesn't exist\n",
    "# if not os.path.exists(folder_path):\n",
    "#     print(f\"Folder Not Found: {folder_path}\")\n",
    "\n",
    "# # Get a list of all parquet files in the folder\n",
    "parquet_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.parquet')])\n",
    "def sorting_key(filename):\n",
    "    # Extract the value after 'checkpoint_'\n",
    "    start_index = filename.find('checkpoint_') + len('checkpoint_')\n",
    "    end_index = filename.find('_to_')\n",
    "    value_str = filename[start_index:end_index]\n",
    "    return int(value_str)\n",
    "\n",
    "# Sort the list using the custom sorting key\n",
    "parquet_files = sorted(parquet_files, key=sorting_key)\n",
    "\n",
    "# if not parquet_files:\n",
    "#     print(\"No parquet files found in the folder.\")\n",
    "#     return None\n",
    "\n",
    "# Read each parquet file and append it to a list\n",
    "dfs = []\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_parquet(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all dataframes\n",
    "merged_df1 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# # Save the merged dataframe\n",
    "# merged_filename = f'merged_{folder_name}.parquet'\n",
    "# merged_filepath = os.path.join(self.data_dir, 'datasets/output', merged_filename)\n",
    "# merged_df.to_parquet(merged_filepath)\n",
    "# print(f\"Merged dataframe saved to {merged_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34d5883e-c85b-4c91-808d-a06f5713d3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11691, 47)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da811492-fc8d-4f6a-b11d-985d783a8a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>run_completed</th>\n",
       "      <th>run_status_code</th>\n",
       "      <th>trackingId</th>\n",
       "      <th>pdfContent</th>\n",
       "      <th>propertyCharacteristics_totalLivingArea</th>\n",
       "      <th>propertyCharacteristics_totalLivingAreaSource</th>\n",
       "      <th>propertyCharacteristics_yearBuilt</th>\n",
       "      <th>propertyCharacteristics_yearBuiltSource</th>\n",
       "      <th>propertyCharacteristics_propertyConstructionType</th>\n",
       "      <th>...</th>\n",
       "      <th>location_longitude</th>\n",
       "      <th>location_inputAddress</th>\n",
       "      <th>roofConditionInsightsScore_riskScore</th>\n",
       "      <th>roofConditionInsightsScore_riskDescription</th>\n",
       "      <th>rci_score_v1.0</th>\n",
       "      <th>rci_score_v1.1</th>\n",
       "      <th>rci_key_triggers</th>\n",
       "      <th>rci_raw_score_v1.0</th>\n",
       "      <th>rci_raw_score_v1.1</th>\n",
       "      <th>historicalRoofPermits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69 SPRING ST, CHESTER, SC 29706</td>\n",
       "      <td>False</td>\n",
       "      <td>204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5237 ROOSEVELT BLVD, PHILADELPHIA, PA 19124</td>\n",
       "      <td>False</td>\n",
       "      <td>204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235 W HOLLAND ST, MINDEN, NE 68959</td>\n",
       "      <td>False</td>\n",
       "      <td>204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6405 TOWLES MILL RD, SPOTSYLVANIA, VA 22551</td>\n",
       "      <td>False</td>\n",
       "      <td>204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847 MICHELTORENA ST, LOS ANGELES, CA 90026</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>InterChange</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>InterChange</td>\n",
       "      <td>Siding, Wood (100%)</td>\n",
       "      <td>...</td>\n",
       "      <td>-118.278697</td>\n",
       "      <td>847 MICHELTORENA ST LOS ANGELES CA 90026</td>\n",
       "      <td>1.5</td>\n",
       "      <td>LOW</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[Ponding, Tree Overhang]</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       address  run_completed run_status_code  \\\n",
       "0              69 SPRING ST, CHESTER, SC 29706          False             204   \n",
       "1  5237 ROOSEVELT BLVD, PHILADELPHIA, PA 19124          False             204   \n",
       "2           235 W HOLLAND ST, MINDEN, NE 68959          False             204   \n",
       "3  6405 TOWLES MILL RD, SPOTSYLVANIA, VA 22551          False             204   \n",
       "4   847 MICHELTORENA ST, LOS ANGELES, CA 90026           True             200   \n",
       "\n",
       "  trackingId pdfContent  propertyCharacteristics_totalLivingArea  \\\n",
       "0       None       None                                      NaN   \n",
       "1       None       None                                      NaN   \n",
       "2       None       None                                      NaN   \n",
       "3       None       None                                      NaN   \n",
       "4       None       None                                   1746.0   \n",
       "\n",
       "  propertyCharacteristics_totalLivingAreaSource  \\\n",
       "0                                          None   \n",
       "1                                          None   \n",
       "2                                          None   \n",
       "3                                          None   \n",
       "4                                   InterChange   \n",
       "\n",
       "   propertyCharacteristics_yearBuilt propertyCharacteristics_yearBuiltSource  \\\n",
       "0                                NaN                                    None   \n",
       "1                                NaN                                    None   \n",
       "2                                NaN                                    None   \n",
       "3                                NaN                                    None   \n",
       "4                             1924.0                             InterChange   \n",
       "\n",
       "  propertyCharacteristics_propertyConstructionType  ... location_longitude  \\\n",
       "0                                             None  ...                NaN   \n",
       "1                                             None  ...                NaN   \n",
       "2                                             None  ...                NaN   \n",
       "3                                             None  ...                NaN   \n",
       "4                              Siding, Wood (100%)  ...        -118.278697   \n",
       "\n",
       "                      location_inputAddress  \\\n",
       "0                                      None   \n",
       "1                                      None   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4  847 MICHELTORENA ST LOS ANGELES CA 90026   \n",
       "\n",
       "   roofConditionInsightsScore_riskScore  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   1.5   \n",
       "\n",
       "   roofConditionInsightsScore_riskDescription  rci_score_v1.0  rci_score_v1.1  \\\n",
       "0                                        None             NaN             NaN   \n",
       "1                                        None             NaN             NaN   \n",
       "2                                        None             NaN             NaN   \n",
       "3                                        None             NaN             NaN   \n",
       "4                                         LOW             1.5             1.5   \n",
       "\n",
       "           rci_key_triggers  rci_raw_score_v1.0  rci_raw_score_v1.1  \\\n",
       "0                      None                 NaN                 NaN   \n",
       "1                      None                 NaN                 NaN   \n",
       "2                      None                 NaN                 NaN   \n",
       "3                      None                 NaN                 NaN   \n",
       "4  [Ponding, Tree Overhang]                 1.5                 1.5   \n",
       "\n",
       "  historicalRoofPermits  \n",
       "0                  None  \n",
       "1                  None  \n",
       "2                  None  \n",
       "3                  None  \n",
       "4                  None  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad1409-8cea-45b0-8e5c-82867fceaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_parquet(\"../data/datasets/output/Checkpoints_20240403_0044/checkpoint_11500_to_12000_20240403_0403_1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdc2234d-43b1-4887-89c8-ca1981951e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_wo_claims = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cf6bfe8-6392-4eea-954b-7ef9793207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/datasets/output/rci_data_checkpoint_3000_20240402_1442.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b12af0b-89c1-4f4b-b4df-db646de22970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/datasets/output/rci_data_checkpoint_3000_20240402_1442.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89e3e178-413d-4efa-b54e-b6aa4439a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1f5ccab-3f24-47d5-b4f8-653e38e14dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_wo_claims = pd.concat([merged_df, df1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fed5bd58-adae-40c7-8d55-e02c52c7bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_status_code\n",
       "200    10263\n",
       "204     4422\n",
       "500        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_wo_claims['run_status_code'] = df_rci_uw_wo_claims.run_status_code.astype(int)\n",
    "df_rci_uw_wo_claims.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045f2ab-cf2d-4649-9ccb-c661a3cf767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find new samples with status 200\n",
    "# eligible_rows = df_rci_uw_wo_claims[df_rci_uw_wo_claims['run_status_code'] != \"200\"]\n",
    "# already_included_addresses = final_sampled_df['full_address'].unique()\n",
    "# new_samples_list = []  # List to collect new samples\n",
    "\n",
    "# for _, row in eligible_rows.iterrows():\n",
    "#     # Extract current row's UW_ZIP\n",
    "#     current_address = row['address']\n",
    "#     current_address_lower = current_address.lower()\n",
    "#     filtered_df['full_address_lower'] = filtered_df['full_address'].str.lower()\n",
    "#     current_zip = filtered_df.loc[filtered_df['full_address_lower'] == current_address_lower, 'UW_ZIP'].iloc[0]\n",
    "\n",
    "#     # current_zip = filtered_df.loc[current_address, 'UW_ZIP']\n",
    "    \n",
    "#     # Filter `filtered_df` for the same UW_ZIP, `claim_exists` == False, and not already included based on `full_address`\n",
    "#     eligible_samples = filtered_df[\n",
    "#         (filtered_df['UW_ZIP'] == current_zip) &\n",
    "#         (filtered_df['claim_exists'] == False) &\n",
    "#         (~filtered_df['full_address'].isin(already_included_addresses))\n",
    "#     ]\n",
    "    \n",
    "#     # Check if there are at least 2 samples to select from\n",
    "#     if len(eligible_samples) >= 2:\n",
    "#         new_samples = eligible_samples.sample(n=2, replace=False)  # Sample 2 new entries\n",
    "#     else:\n",
    "#         # If not enough samples, take what is available\n",
    "#         new_samples = eligible_samples\n",
    "    \n",
    "#     # If new_samples is not empty, proceed\n",
    "#     if not new_samples.empty:\n",
    "#         # Update the list of already included addresses to prevent re-selection\n",
    "#         already_included_addresses = np.concatenate((already_included_addresses, new_samples['full_address'].unique()))\n",
    "        \n",
    "#         # Collect the new samples\n",
    "#         new_samples_list.append(new_samples)\n",
    "\n",
    "# # Concatenate all new samples into a DataFrame\n",
    "# new_samples_df = pd.concat(new_samples_list).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac46549-3149-4a12-ad51-2c02f44960bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_samples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9651c-3a04-45a1-bc8d-1ecdf4365a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_sample_addresses = new_samples_df.loc[new_samples_df.claim_exists == 0, 'full_address'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aababc37-c82f-490e-aeec-3f6f0fc021e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rci = RoofConditionInsights(\n",
    "#     env=\"PRD\",\n",
    "#     api_key=\"79802C81EF4C49C5A24F202BF3BB5219\",\n",
    "#     api_companyid=\"3168675050\",\n",
    "#     username=\"all@vod.com\",\n",
    "#     password=\"myriadvod123456\"\n",
    "# )\n",
    "# st = time.time()\n",
    "# df_rci_uw_wo_claims2 = rci.process_multiple_addresses(new_sample_addresses, generate_pdf=False, save_json=True)\n",
    "# et = time.time()\n",
    "# print('Processing time', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545907c8-2983-4ce7-b803-8d9e972efdab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_rci_uw_wo_claims = pd.read_csv('../data/datasets/output/df_rci_wo_claim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288d0e1-e342-4f8a-8be2-c9f5611377de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rci_uw_wo_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07d38844-8d5c-46b7-81fc-bc55581ff01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_claims = pd.read_csv('../data/datasets/output/claim_data_2023_UW_Q4_allstate_prod_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4bc4d-01a1-44cd-8267-802039bff0ff",
   "metadata": {},
   "source": [
    "# MERGE CLAIM AND NO CLAIM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "652decbe-ee9c-4d2f-a63b-a95c16dc96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final = pd.concat([df_rci_uw_w_claims, df_rci_uw_wo_claims, merged_df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b205817f-13af-4770-8f3e-5fd56cb3a2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21657, 49)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_wo_claims_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c46fcfbe-276d-42ca-b3d9-fc738434002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final = df_rci_uw_w_wo_claims_final[df_rci_uw_w_wo_claims_final['run_completed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de88a148-57e8-45c1-9e4d-e8b28b39df66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14414"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_wo_claims_final['address'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a5da936-6bc2-4c41-a59b-cdcd5b9dd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final = df_rci_uw_w_wo_claims_final.drop_duplicates(subset='address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b7ac2445-db46-44d2-b9e0-cc818d696014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_status_code\n",
       "200    14414\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_wo_claims_final.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "12ccd637-7530-47a7-af95-80a4154de201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14414, 49)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_wo_claims_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0114ba8a-8480-41e6-8744-2c4f546c4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final = df_rci_uw_w_wo_claims_final.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "54df6a28-aaab-4527-b601-46a2bfdc5338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14414, 47)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rci_uw_w_wo_claims_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "49b44c66-6b1b-408e-9734-e5dd3a7e7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final.to_csv('../data/datasets/output/all_data_2023_UW_Q4_allstate_superset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "402f8635-f551-44e2-b85d-55b278d9c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/datasets/output/all_data_2023_UW_Q4_allstate_superset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bce80b80-f88f-4952-8da2-ea1959576fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_parquet('../data/datasets/output/all_data_2023_UW_Q4_allstate_superset.parquet', \n",
    "               engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2acca0a4-ad81-4d7e-8edb-b235c5d14d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_parquet('../data/datasets/output/all_data_2023_UW_Q4_allstate_superset.parquet', \n",
    "               engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b149ff7c-d1fb-416d-a679-8d5e9ad369ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14414, 48)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5cae27ce-5327-44bc-b4ac-e3e63e3c2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14414, 48)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "08aab8fb-a7b7-493b-88e5-4f77e0abbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e37b1-76dd-419f-8724-02e8c8183759",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7cb1999a-dc15-4583-bcf1-1b55996a78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv('../data/datasets/output/rci_claim_23_uw_22Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54d0b5-cebd-4f90-af81-8993e3b02f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t2 = pd.read_parquet('../data/datasets/output/all_data_UWQ4_claim2023_data_allstate_superset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8b6b9-cdb3-4019-a766-1131304b89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_parquet('../data/datasets/output/all_data_UWQ4_claim2023_data_allstate_superset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fc4f04b3-79f5-4a99-b43f-4503b7c58bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final = df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fbf98ee7-5ab9-49c4-992e-e719a01b734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final['address_lower'] = df_rci_uw_w_wo_claims_final['address'].str.lower()\n",
    "df_claims_UW['full_address_lower'] = df_claims_UW['full_address'].str.lower()\n",
    "merged_df = pd.merge(\n",
    "    left=df_rci_uw_w_wo_claims_final,\n",
    "    right=df_claims_UW,\n",
    "    how='left',\n",
    "    left_on='address_lower',\n",
    "    right_on='full_address_lower'\n",
    ")\n",
    "merged_df.drop(columns=['address_lower', 'full_address_lower'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c0b1c9b5-72c6-4122-8764-914b65a5bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_parquet('../data/datasets/output/all_data_UWQ4_claim2023_data_allstate_superset.parquet',\n",
    "                    engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479523bf-2d44-49f1-85da-57a14f9d32bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14415, 60)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_tmp = pd.read_parquet('../data/datasets/output/all_data_UWQ4_claim2023_data_allstate_superset.parquet',\n",
    "                    engine='pyarrow')\n",
    "merged_df_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964b450-59d2-485b-a51e-5ad5e331c26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claim_exists\n",
       "0    12076\n",
       "1     2339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_tmp.claim_exists.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01134baf-3ece-49e3-af3a-117045909b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14414"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_tmp.address.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e2dc7-9932-4db2-bde0-61ab2d21fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# balanced_dfs = []\n",
    "\n",
    "# # Ensure DataFrame columns for comparison are in the correct type\n",
    "# merged_df['claim_exists'] = merged_df['claim_exists'].astype(bool)\n",
    "\n",
    "# for zip_code in merged_df['UW_ZIP'].unique():\n",
    "#     df_zip = merged_df[merged_df['UW_ZIP'] == zip_code]\n",
    "#     corresponding_state = df_zip['UW_STATE'].iloc[0]  # Assuming all rows in a ZIP code share the same state\n",
    "    \n",
    "#     true_count = (df_zip['claim_exists'] == True).sum()\n",
    "#     false_count = (df_zip['claim_exists'] == False).sum()\n",
    "    \n",
    "#     # If there are more false claims than true claims, downsample false claims\n",
    "#     if false_count > true_count:\n",
    "#         df_zip_false = df_zip[df_zip['claim_exists'] == False].sample(n=true_count, replace=False)\n",
    "#         df_zip_true = df_zip[df_zip['claim_exists'] == True]\n",
    "#         df_zip = pd.concat([df_zip_true, df_zip_false])\n",
    "    \n",
    "#     # Calculate the shortfall of false claims if there are more true claims than false claims\n",
    "#     elif true_count > false_count:\n",
    "#         shortfall = true_count - false_count\n",
    "#         additional_false = merged_df[(merged_df['UW_STATE'] == corresponding_state) & \n",
    "#                                      (merged_df['claim_exists'] == False) & \n",
    "#                                      (~merged_df['full_address'].isin(df_zip['full_address']))]\n",
    "        \n",
    "#         if len(additional_false) >= shortfall:\n",
    "#             additional_false = additional_false.sample(n=shortfall, replace=False)\n",
    "#         df_zip = pd.concat([df_zip, additional_false])\n",
    "    \n",
    "#     balanced_dfs.append(df_zip)\n",
    "\n",
    "# balanced_merged_df = pd.concat(balanced_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b6698-ef2e-4386-a2f4-d03239916da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def balance_data(merged_df, method='zip'):\n",
    "    balanced_dfs = []\n",
    "\n",
    "    # Ensure DataFrame columns for comparison are in the correct type\n",
    "    merged_df['claim_exists'] = merged_df['claim_exists'].astype(bool)\n",
    "\n",
    "    if method == 'zip':\n",
    "        for zip_code in merged_df['UW_ZIP'].unique():\n",
    "            df_zip = merged_df[merged_df['UW_ZIP'] == zip_code]\n",
    "            corresponding_state = df_zip['UW_STATE'].iloc[0]  # Assuming all rows in a ZIP code share the same state\n",
    "\n",
    "            true_count = (df_zip['claim_exists'] == True).sum()\n",
    "            false_count = (df_zip['claim_exists'] == False).sum()\n",
    "\n",
    "            # If there are more false claims than true claims, downsample false claims\n",
    "            if false_count > true_count:\n",
    "                df_zip_false = df_zip[df_zip['claim_exists'] == False].sample(n=true_count, replace=False)\n",
    "                df_zip_true = df_zip[df_zip['claim_exists'] == True]\n",
    "                df_zip = pd.concat([df_zip_true, df_zip_false])\n",
    "\n",
    "            # Calculate the shortfall of false claims if there are more true claims than false claims\n",
    "            elif true_count > false_count:\n",
    "                shortfall = true_count - false_count\n",
    "                additional_false = merged_df[(merged_df['UW_STATE'] == corresponding_state) &\n",
    "                                             (merged_df['claim_exists'] == False) &\n",
    "                                             (~merged_df['full_address'].isin(df_zip['full_address']))]\n",
    "\n",
    "                if len(additional_false) >= shortfall:\n",
    "                    additional_false = additional_false.sample(n=shortfall, replace=False)\n",
    "                df_zip = pd.concat([df_zip, additional_false])\n",
    "\n",
    "            balanced_dfs.append(df_zip)\n",
    "\n",
    "    elif method == 'state':\n",
    "        for state in merged_df['UW_STATE'].unique():\n",
    "            df_state = merged_df[merged_df['UW_STATE'] == state]\n",
    "\n",
    "            true_count = (df_state['claim_exists'] == True).sum()\n",
    "            false_count = (df_state['claim_exists'] == False).sum()\n",
    "\n",
    "            # If there are more false claims than true claims, downsample false claims\n",
    "            if false_count > true_count:\n",
    "                df_state_false = df_state[df_state['claim_exists'] == False].sample(n=true_count, replace=False)\n",
    "                df_state_true = df_state[df_state['claim_exists'] == True]\n",
    "                df_state = pd.concat([df_state_true, df_state_false])\n",
    "\n",
    "            # Calculate the shortfall of false claims if there are more true claims than false claims\n",
    "            elif true_count > false_count:\n",
    "                shortfall = true_count - false_count\n",
    "                additional_false = merged_df[(merged_df['UW_STATE'] == state) &\n",
    "                                             (merged_df['claim_exists'] == False) &\n",
    "                                             (~merged_df['full_address'].isin(df_state['full_address']))]\n",
    "\n",
    "                if len(additional_false) >= shortfall:\n",
    "                    additional_false = additional_false.sample(n=shortfall, replace=False)\n",
    "                df_state = pd.concat([df_state, additional_false])\n",
    "\n",
    "            balanced_dfs.append(df_state)\n",
    "\n",
    "    elif method == 'national':\n",
    "        true_count = (merged_df['claim_exists'] == True).sum()\n",
    "        false_count = (merged_df['claim_exists'] == False).sum()\n",
    "\n",
    "        # If there are more false claims than true claims, downsample false claims\n",
    "        if false_count > true_count:\n",
    "            df_false = merged_df[merged_df['claim_exists'] == False].sample(n=true_count, replace=False)\n",
    "            df_true = merged_df[merged_df['claim_exists'] == True]\n",
    "            merged_df = pd.concat([df_true, df_false])\n",
    "\n",
    "        # Calculate the shortfall of false claims if there are more true claims than false claims\n",
    "        elif true_count > false_count:\n",
    "            shortfall = true_count - false_count\n",
    "            additional_false = merged_df[merged_df['claim_exists'] == False].sample(n=shortfall, replace=False)\n",
    "            merged_df = pd.concat([merged_df, additional_false])\n",
    "\n",
    "        balanced_dfs.append(merged_df)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid balancing method. Choose from 'zip', 'state', or 'national'.\")\n",
    "\n",
    "    balanced_merged_df = pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "    return balanced_merged_df\n",
    "\n",
    "# Usage example:\n",
    "# method: 'zip', 'state', or 'national'\n",
    "balanced_df = balance_data(merged_df, method='national')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e501765-dd08-4495-87c8-038ea01f4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = os.path.join(DATA_DIR, 'datasets/output/rci_claim_23_uw_22Q4.csv')\n",
    "balanced_merged_df.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67feab-3bf8-4867-b6ac-5246028323c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rci_uw_w_wo_claims_final.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fd28f-3a88-4112-8516-ea6a83a71a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_merged_df.run_status_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7522b-431e-4a02-8cbb-4eb6f5854a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_merged_df['claim_exists'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c6ddd-beb5-4eed-97b7-d9636616a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cols = [col for col in balanced_merged_df if 'score' in col.lower() or 'condition' in col.lower()]\n",
    "balanced_merged_df.loc[balanced_merged_df.address=='5416 MORELLA AVE, VALLEY VILLAGE, CA 91607', score_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbb6ca-175c-45d8-bd6e-8100892e00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neq_cond = balanced_merged_df['score_v1.0'] != balanced_merged_df['roofConditionInsightsScore_riskScore']\n",
    "balanced_merged_df[neq_cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50face-9213-4d55-a10c-be2eac4b64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_merged_df.loc[balanced_merged_df.address=='5416 MORELLA AVE, VALLEY VILLAGE, CA 91607', 'roofCharacteristics_roofConditions'][196]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "settleassist",
   "name": "tf2-cpu.2-8.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-8:m112"
  },
  "kernelspec": {
   "display_name": "settleassist",
   "language": "python",
   "name": "settleassist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
